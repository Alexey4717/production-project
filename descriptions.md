при создании репо
скопировать git remote add origin <название репо>
потом локально git init
и создать удаленный репо скопированной командой

Командой git status можно увидеть какие файлы распознает гит для отправки в удаленный репо

Cоздание собственного сниппета для быстрого разворачивания функционального реакт компонента.
В Webstorm. Settings -> Editor -> Live template. Там user/. (добавить свой), ввести название команды.
Сниппет:

import classNames from 'shared/helpers/styles/classNames/classNames';
import cls from './$FILE_NAME$.module.scss';

interface $FILE_NAME$Props {
    className?: string;
}

export const $FILE_NAME$ = (props: $FILE_NAME$Props) => {
    const {
        className,
    } = props;
    return (
        <div classname={classNames(cls.$FILE_NAME$, {}, [className])}>

        </div>
    );
};

Правой кнопкой мыши выделяется переменная, настройка. Выбрать fileNameWithoutExtension().
Выбрать контекст JavaScrip/TypeScript (при наличии React JS/TS).

Сниппет для .vscode/rc.code-snippets

{
"React Functional Component": {
"prefix": [
"rc"
],
"body": [
"import { classNames } from \"shared/lib/classNames/classNames\";",
"import cls from \"./$TM_FILENAME_BASE.module.scss\";",
"",
"interface $TM_FILENAME_BASE Props {",
"  className?: string;",
"}",
"",
"export const $TM_FILENAME_BASE = ({ className }: $TM_FILENAME_BASE Props) => {",
"  return (",
"    <div className={classNames(cls.$TM_FILENAME_BASE, {}, [className])}>",
"      $2",
"    </div>",
"  )",
"};",
""
],
"description": "React Functional Component"
}
}

В какой-то момент я начал использовать yarn вместо npm, т.к. с ним комфортнее работать со старыми версиями пакетов.
Возникает меньше конфликтов версий, более стабильная работа.

18. Настройка eslint для ts файлов
К настройкам правил нужно относиться серьезно и основательно
npm install --save-dev eslint
npm init @eslint/config
Для настройки правил eslint, наводим на ошибку линта, копируем название правила и гуглим этот rule,
потом вставляем эти правила в .eslintrc.js в поле rules
Если мы знаем что это за правило и оно нам не нужно,
то можно просто указать его название в ключе rules со значением 'off'.
Либо можно сменить отображение на предупреждение (значение 'warn')
Команда eslint "**/*.{ts,tsx}" --fix должна фиксить все ошибки на проекте
Если осознанно хочется заблокировать правило в одном месте, можно над ним вставлять комментарий 
// eslint-disable-next-line <название правила>

19. Stylelint для настройки правил css файлов, конфиг в .stylelintrc.json
Для подсветки текста в jsx разметки для i18n (что нужен перевод) установлен eslint-plugin-i18next
в конфиге .eslintrc.js нужно добавить murkupOnly: true
в plugins: i18next
в extends: plugin:i18next/recommended

20. Jest - библиотека для тестирования js кода (jsdom)
Можно написать jest --init для автонастройки. Также нужно установить @types/jest.
Чтобы jest понимал ts, нужно установить @babel/preset-typescript. и обновить конфиг @babel
Для тестирования, рядом с тестируемыми файлами создаем файл с расширением .test.ts
Можно запускать тесты только для 1 файла через пробел после скрипта <название файла>

21. Несуществующий роут, page компонент для роута, которого нет в Routes
loader cкопирован с источника https://loading.io/css/

22. ErrorBoundary не отлавливает ошибки, которые происходят в асинхронном коде, в событиях,
при server-side rendering и ошибки, которые возникают в самом ErrorBoundary.
В componentDidCatch можно использовать свой сервис для логирования, а не console.log.
В классовом компоненте нужно испольщовать HOK withTranslation from react-i18next

23. Webpack Bundle Analyzer - пакет для анализа бандла вебпака
Нужно добавить плагин BundleAnalyzerPlugin в конфиг
После этого, при запуске приложения, во второй вкладке ана порту :8888 откроется страница с описаниями пакетов, 
которые используются в приложении.
Если запускать сборки run build:dev run build:prod, то так же будет открываться страница с пакетами билдов
Слева сверху можно посмотреть вес чанков в разных режимах

24. React testing library. Файлы с тестами желательно располагать рядом с компонентами или функциями
Чтобы jest тесты работали с абсолютными импортами добавили в jest.config modulePaths: ['<rootDir>src']
возле jest config создали файл setupTests.ts (при create-react-app он так и называется)
в jest.config добавили setupFilesAfterEnv: ['<rootDir>config/jest/setupTests.ts'],
в tsconfig добавили "include": ["./config/jest/setupTests.ts"],
после этого TS подхватывает все методы при написании кода в рантайме
так же нужно установить пресет для парсинга tsx - @babel/preset-typescript и @babel/preset-react(эта версия не нашлась, возможна ошибка)
Для парсинга jest`ом css модулей установили identity-obj-proxy
в конфиге jest добавили moduleNameMapper: { '\\.s?css$': 'identity-obj-proxy' }
В babel конфиге изменили ["@babel/preset-react", {"runtime": "automatic"}]
Можно добавить в тестах screen.debug(); Тогда в консоли отобразятся атрибуты элемента
Для парсинга svg в jest.config в поле moduleNameMapper добавили '\\.svg': path.resolve(__dirname, 'jestEmptyComponent.tsx'),
Грубо говоря это мок, который будет использоваться для всех импортов в которых используется svg. Создали рядом с конфигом этот компонент
в setupTests.ts добавили import 'regenerator-runtime/runtime'; и установили зависимость regenerator-runtime
В shared/config/i18n дабавили i18nForTests.ts (скопировали из https://react.i18next.com/misc/testing#example-configuration-for-testing  и немного изменили)
создали в shared/lib/test/renderWithTranslation helper
Эта функция оборачивает тестируемый компонент в обертку и добавляет нужную конфигурация для переводов

25. Storybook. Инициализация npx sb init --builder webpack5
После инициализации появится папка .storybook (конфиг).
И появятся 2 новых скрипта в package.json для запуска и сборки storybook.
Так же появится директория src/stories. В будущем будут писаться свои stories.
Можно будет передавать в компоненты разные пропсы.
Вынесли конфигурацию с src/.storybook в src/config/storybook
Изменили в конфиге относительные пути
добавили в скрипты флаг -c ./config/storybook с новым (не дефолтным) путем до конфига
Новые сторисы создаются в папке компонента рядом с файлом компонента 
с расширением <component-name>.stories.tsx (как в main конфиге для сторис)
Перенесли код из файла сторис примера в нащ новый файл, сгенеренную папку src/stories удалили
По сути большенство это копипаста и переписывание пропсов
в meta.title указывается путь и азвание файла (title: 'shared/Button') - shared слой и Button компонент
Так же storybook по-дефолту не понимает настроенные на проекте абсолютные пути в импортах, нужна доп настройка
У сторибука есть своя конфигурация для вебпака. На занятии создавали сами (файл webpack.config.ts), 
это обычный файл конфига для вебпак, но отдельный
Я поставил новую 8 версию и она была уже после инициализации сторибука (находится возле остальных файлов конфига)
У меня конфиг уже был рабочий, с настройкой абсолютных путей config.resolve.modules.push(paths.src);
Так же нужна настройка CSS модулей для сторибука (по-дефолту был импорт в конфиге, но не адаптирован под мой конфиг)
В config/build/buildLoaders.ts есть cssLoader. Решили вынести лоадеры в отдельную папку config/build/loaders
Вынесли туда в файл buildCssLoader.ts
Если верстка компонента в сторибуке не соответствует, можно так же открыть девтулзы и посмотреть DOM 
Storybook не подтягиев ссылки на переменные препроцессора стилей по дефолту. 
Чтоб не импортировать в каждый сторис файл с переменными в стилях
нужно в конфиге сторибука preview.ts добавить decorator,
который будет глобально оборачивать каждый сторибук компонент
В shared/config создаем папку storybook.
Добавили декоратор темы в preview.ts (Глобадьно применяется LIGHT, но в каждый сторис можно добавлять другой).
Так же в вебпак конфиг сторис нужно добавлять svg модуль (т.к. это отдельный конфиг).
Сторибук будет полезен разработчикам, они могут ознакомиться с компонентами
Так же с помощью сторибука можно снимать скриншотные тесты и делать регрессионное тестирование интерфейса на изменение
Добавили декоратор роутера
Для pages так же сделали сторисы

26. Скриншотные тесты. Есть платные и бесплатные библиотеки. Тут используется Loki. 
Инициализация - Сначала установка пакета loki в devDep, потом npx loki init --config <путь до конфига storybook>
В package.json добавится конфигурация loki
Скрины будут сниматься на ноуте в хроме и iphone на хроме (судя по конфигам)
Меняем там в target с docker на app (Если работа в linux или macOS)
На винде могут быть проблемы с запуском (если так, то нужно вернуть target docker и запустить приложение docker на ПК)
Мне так же пришлось поднять версию loki до 0.29.0, т.к. под капотом 0.28.0 использовала 16 версию react и были конфликты
Для работы с loki сначала нужно запустить storybook
Для скриншотного тестирования необходимо выполнить команду npx loki test
После успешного выполнения тестов появится папка .loki со скриншотами в виде png разных компонентов в разных состояниях
При изменении чего-то в компонентах и прогоне повторных тестов, часть тестов упадет, т.к. они будут сравниваться со старыми скриншотами
в папке difference. 
При наличии различий в difference можно запустить скрипт report, чтоб сгенерить новые файлы (json и html), и там более наглядно посмотреть различия.
Регрессионное тестирование - когда мы убеждаемся, что новый функционал не сломал старый.
Так же скриншотные тесты помогают определить, что в сторибуке что-то не так, т.к. они снимаются на основании сторибука.
Скриншоты отправляются в удаленный репозиторий.
Добавили скрипт test:ui для скриншотных тестов и test:ui:ok для одобрения скриншотов (т.е. когда loki отловил ожидаемые изменения,
изменения которые осознанно сделаны и мы их подтверждаем)
Скриншотные тесты используют разные движки (по скорости) - https://loki.js.org/configuration.html.
default - pixelmatch движок.

27. У нас стало появляться много скриптов (линтеры, сборка, разные виды тестирования, сборка сторибука).
Запускать это вручную становится неудобно. Хочется автоматизировать процесс запуска этих скриптов.
Будем использовать Github-actions для настройки CI/CD.

CI/CD переводится как непрерывная интеграция и непрерывное развертывание (доставка).
Это конвейер, который позволяет автоматизировать рутинные процессы
(сборка приложения, прогон тестов, прогон линтеров, проверка типизации (CI) / деплой, релиз (CD) и т.д.).

Сначала CI.
CI процессы обычно запускаются скриптами, описанными в package.json.
Нужна автоматизация чтобы:
- Не делегировать эту ответственность (ручной запуск скриптов) на разработчика и нивелировать человеческий фактор
- Не загружать разработчика лишней работой (т.к. она стоит дорого)
- Повышение надежности приложения в целом
Хотелось бы, чтобы при создании pull request (PR) и при последующих коммитах в ветку
автоматически запускались бы все эти процессы (сборка, тесты, линтеры и пр. проверки (CI), которые необходимы в нашем приложении)
и чтобы мы не могли вмерджить ветку в main до тех пор, пока мы не убедились, что все эти процессы отработали без ошибок.
И если хотябы 1 из таких проверок упала, то нам нужно запретить merge в основную (main) ветку, чтобы не сломать код.

Настройка:
Примеры для настройки можно брать из guthub, либо сделать запрос github actions frontend, chat-gpt и т.д.
Создали папку .github в корне приложения, а внутри неё папку workflows (рабочий процесс).
Далее нужно внутри этой папки создать файл с расширением .yml (название любое).
Скопируем пример кода для файла из https://docs.github.com/ru/actions/writing-workflows/quickstart
Далее отдельным коммитов нужно запушить yml файл в github (commit m: "add main pipeline github actions")
Потом заходим в github репозиторий / actions.
Там будет этот workflow, в который можно провалиться и посмотреть на процессы, описанные в yml файле.
В начале скрипты будут в виде echo (т.е. логи текстов, моки для проверки). 
Там могут быть любые сложные скрипты, например npm run build.
В файле main.yml поменяли name: linting, testing, building.
В начале укажем что все проверки будут запускаться на push в ветку master и при создании pull_request.
Далее нужно описать jobs. Удаляем старую.
Создадим новую с названием pipeline (можно называть как угодно).
В поле runs-on указывается ОС, в которой будет запускаться job.
Затем необходимо указать версию NodeJS, которая будет использоваться
Для работы с фронтом, нужно всегда устанавливать в первую очень NodeJS, чтобы код мог работать.
В steps указаны наши скрипты
Там (после стэпов по установке NodeJS) первым делом нужно установить node_modules.
Далее можно например запускать сборку
Потом сделаем запуск скрипта линтера для ts, потом линтер для css, потом все виды тестов, потом сборку storybook.
Далее пушим в репозиторий, наблюдаем как выполняются jobs. (появится желтая точка в репозитории, из неё перейти быстрее).
Bundle-analyser отключил, т.к. он не дает завершиться процессу сборки.
В документации loki есть описание интеграции unit тестов в CI pipeline (https://loki.js.org/continuous-integration.html).
В начале нужно сделать сборку storybook, потом на основании этой сборки (storybook-static) можно делать скриншоты.
Т.е. запускать его в CI pipeline не обязательно. Добавили сборку в gitignore.
И добавили скрипт test:ui:ci для loki, который будет запускаться после сборки storybook и снимать с неё скриншоты.
Не забываем добавить скрипты в yml файл

Далее когда CI закончен без ошибок, мы мерджим код в main ветку, затем идёт сборка приложения (если это требуется).
И дальнейшая публикация этой сборки на тестовое или прод окружение (CD).
Т.е. CI/CD касается как ежедневных процессов (для тестирования), так и еженедельных (смотря какой спринт, релиз на прод).
Так же можно отдельно ознакомиться с темой CI/CD тут https://www.youtube.com/watch?v=ANj7qUgzNq4

28. Тут особо нового ничего не делали, только улучшили UI Sidebar. Добавили размеры кнопке. Сторисы для них.
Был нюанс, после пуша в репозиторий упали unit тесты.
Следующие тесты не запустились, т.к. конфиг был настроен так, что jobs выполняются последовательно.
Если одна из них падает, то следующие не запускаются. Нужно в step добавить проверку if: always(), чтобы они запускались в любом случае.
Сделали это для всего, что может идти последовательно (билд, линтеры, тесты, кроме инсталяции пакетов в начале).
Так же был изменён компонент Sidebar, там добавились ссылки, но не адаптировали тесты.
Примерно такая же проблема решалась для сторибука, делался декоратор с роутером.
Сделали похожую штуку для jest (unit) тестов.
В папке shared/lib/tests создали файл componentRender/componentRender.ts.
ComponentRender - одна единственную функцию. Будем её везде для unit-тестов использовать.
Т.к. зачем 2 разные функции работающие отдельно. 
Если в случае с декораторами это ещё можно понять, то в случае рендера это избыточно.
Так же упали сткриншотные тесты. Когда компоненты будут нагружены, смотреть скриншоты будет тяжело.
Есть инструмент reg-cli для сравнения скриншотов. Добавили пакет в devDep.
Создали папку scripts. Там будут храниться все скрипты, которые связаны с приложением (генератор бандлов, генератор отчетов и т.п.).
Создали там файл generate-visual-json-report.js. Нужно понимать что он находится вне src, поэтому через babel не проходит.
Нужно писать js в чистом виде (require вместо import и т.п.). Так же могут быть не доступны некоторые веб апи.
Добавили скрипты в package.json.
test:ui:json - генерит файл .loki/report.json, но он не удобен для чтения.
test:ui:html - генерит html отчет (используя json) с интерфейсом, который удобен для чтения и сравнения скриншотов.
test:ui:report - объединяет эти 2 скрипта.
Можно каждый скриншот открыть и посмотреть наглядно, какие произошли изменения.
Так же нужно указать в .gitignore эти сгенеренные отчеты, т.к. там они не нужны.
Подтвердили скрины (test:ui:ok скриптом), чтобы прошли CI.

29. Модальные окна. Реализация через порталы.
Есть несколько способов для отображения/скрытия модалки. 
Первый это opacity: 0 и pointer-events: none (с возвратом на 1 и auto).
Второй это через z-index: -1 (с возвратом обратно).
С помощью transform: scale добавили плавную анимацию открытия модалки.
Для анимации закрытия пришлось писать js, т.к. одним css не справиться.
Так же добавили закрытие на кнопку Esc.
Есть linter правила для react хуков (https://legacy.reactjs.org/docs/hooks-rules.html#eslint-plugin) - есть в CRA по дефолту.
Поставили правило 'react-hooks/exhaustive-deps': 'error' для массивов зависимостей react хуков.
С ним будут подсказки, что в массиве зависимостей отсутствуют нужные зависимости либо присутствуют лишние.
Семантически правильно помещать компонент модального окна в самый верх. С этим поможет концепция порталов.
В shared слое создали Portal, который можно удобно переиспользовать.
Обернули им Modal, теперь модалка рядом с root папкой с react-app.
Но из-за этого не будут доступны глобальные стили и т.д., 
т.к. модалка находится вне приложения, а все завязано на App (там импорты и т.д.).
Перенесли импорт стилей в index.ts, а в глобальных стилях перенесли определения vars в body из .app класса.

30. Redux-toolkit. Если устанавливать redux-toolkit, то отдельно redux устанавливать не нужно.
Тулкит нужен для уменьшения бойлерплэйт кода (не нужно создавать экшены, экшен-криэйтэры...).
Внутри есть библа immerJs, которая позволяет изменять state.
Так же с коробки есть redux-thunk и инструменты разработчика, их не нужно ставить отдельно.
Чтоб редакс работал нужно все приложение обернуть в провайдер.
Создадим app/providers/StoreProvider(ui/config).
В конфиге будет конфигурация провайдера редакса (корневые редьюсеры, мидлвэры, вкл/откл тулзы и т.д.).
Для RouterProvider был вынесен конфиг в shared, т.к. роуты используются всеми уровнями компонентов.
Но для StoreProvider конфиг сделали рядом с ним в этой же папке.
Вынесли configureStore в createReduxStore, чтобы можно было переиспользовать (для Storybook, jest и т.п.).
Девтулзы включаем только в режиме разработки (из глобального флага).
Создали интерфейс StateSchema, в котором будет описание типов глобального состояния (передается в джинерике в конфигурацию стора).
Так же создали первую сущность в entities/Counter. В ней сегменты ui и model.
model будет отвечать за state, операции с этим state. ui - это непосредственно компонент.
В model будут папки slice (со слайсом редакса), selectors (с селекторами, которые достают данные) и types (типы данных).
Все типы стэйта будем называть с окончанием Schema (т.е. это часть схемы).
По методологии иногда типы могут импортироваться из вышестоящего слоя (например в models импорт из app).
createSelector из toolkit (под капотом reselect внутри тулкита) позволяет переиспользовать другие селекторы.
Он хорош тем, что, во-первых, не нужно дублировать код.
Во-вторых, мемоизирует значение (зависимость - данные, возвращаемые переданным селектором).
В-третьих, можно использовать несколько селекторов, комбинировать/объединять их и в одной функции получать одно значение.
тип DeepPartial из тулкита позволяет типизировать стейт с отдельным куском.
для каждого редьюса, слайса пишутся тесты. 
Если какое-то поле кто-то поменяет, то тест упадет, может предотвратиться баг.
Т.к. будем писать много тестов, то сделали сниппет (ts)

describe('$FILE$', () => {
    test('', () => {
        expect().toEqual();
    });
});

Добавили в componentRender обертку StoreProvider, чтоб мы смогли тестировать компоненты использующие стор.
Добавили в jest.config globals, для определения __IS_DEV__ глобальной переменной, т.к. jest этого не видет.
Не видит потому, что тестовая среда отличается от среды, которую настраивали в webpack. 
Поэтому глобальные переменные, настройки и т.п. надо делать отдельно.
При тестировании UI для Counter.test.tsx у меня возникла проблема с userEvent. Устарело апи.
Пришлось установить пакеты @testing-library/user-event и @testing-library/dom.
import userEvent from '@testing-library/user-event';
const user = userEvent.setup();
await user.click(screen.getByTestId('some-element'));

31. В этом модуле правки глобальных стилей для модалки.
Передали theme в classNames, как строку в массив additional, т.к. это глобальный селектор класса, то он будет доступен.
Изменили названия тем в енамке Theme (уникализировали), чтоб уменьшить вероятность ошибок (app_light_theme вместо light).
И в themes стилях напрямую обращаемся к селектору .app-dark-theme (а не .app.dark).
Пришлось очистить localStorage, чтоб обновить значение строки.
В хуке useTheme сделали document.body.className = newTheme вместе с сетом в состояние и localStorage.
Тогда они действительно станут глобальными стилями в body.

31.1. Имитация бекенда (JSON server).
Есть сервис jsonplaceholder, с помощью которого можно получать разные данные (https://jsonplaceholder.typicode.com/).
Он спроектирован на базе https://github.com/typicode/json-server, который можно быстро настроить и поднять.
Установили пакет json-server (глобально и локально как дев зависимость), 
добавили в корень папку с файлом json-server/db.json.
Проверить запуск сервера можно командой json-server --watch ./json-server/db.json --port 8000
Этот сервер можно гибко настраивать и поначалу в нём нет механизма авторизации, но её можно добавить.
Сделана имитация авторизации. Создали json-server/index.js.
С фронта будет отправляться захардкоженная строка, а сервер будет её проверять (подобие токена).
При разлогинивании на фронте, будет эта строка удаляться.
Создали скрипт "start:dev:server": "node ./json-server/index.js"
Работать будет так. Отправляется post запрос на /login с указанием username и password.
Если пользователь находится, то он возвращается с id. Этот id используется как ключ.
Пока что проверка авторизации только по наличию строки в заголовке запроса (Authorization), без проверки.

32. Создание кастомного инпута для авторизации. Создали entities/User. Там слайс model. 
Это всё что связано с пользователем (со стором, стэйтом, получение данных о пользователе, реализация редьюсеров...).
Создали первую feature - AuthByUsername. Называются как глаголы, фичи будут использовать слой ниже entities.
Архитектурно такая же файловая структура как и в других слоях, есть public api для максимальной изолированности слоёв,
то что не передаётся из public api изолировано и не используется все слоя.
ui, lib, model и т.д. К каждому слою относятся своя логика, не разбрасывается по всему проекту, а хранится рядом.
Создали в shared слое компонент input.
Сделали lazy пропс в модалке, для формы авторизации (и других компонентов, для которых необходим ленивый рендер модалки 
или в неё требуется поместить асинхронный компонент, который нужно подгружать тогда, когда подгружается модалка). 
Т.к. модалка монтируется в DOM дерево в самом начале, когда мы нажимаем на кнопку войти, фокус из инпута теряется.
Так же уменьшается размер бандла, пока такая модалка не открыта. Регулируется это поведение при помощи lazy в props модалки.

33. Husky. Это пакет, который предназначени для пре-коммит хуков гита. 
Т.е. на какое-то гит действие (git commit, git push) можно повесить какие-то проверки, аналогично тем, которые в github-actions. 
Инициализация npx husky-init
Появилась папка в корне проекта .husky. Для примера есть файл pre-commit, там можно запускать что угодно, 
но обычно запускают только линтеры (что-то легкое, что выполняется быстро).
Потому что запускать всё подряд (сторибук, тесты и т.д.) это очень долго
и на каждый коммит это делать неудобно. Но мы добавили все, т.к. github-actions бесплатно дает лимитированное число проверок.
Поэтому будем делать их тут на прекоммит. Но нужно запускать сторибук локально, 
т.к. в github-actions делалась сборка и на основании неё уже скриншотные тесты.

34. Авторизация. В фиче AuthByUsername
loginReducer сделали необязательным параметром, т.к. будет подгружаться асинхронно.
В папке services бизнес логи с asyncThunk. Там создадим первый loginByUsername вместе с файлом test.
Для запросов на сервер используем axios.
Ошибки обрабатываются в санках с thunkAPI.rejectWithValue. Вообще из thunkAPI можно получить dispatch, 
редьюсер для получения данных и стора и т.д.
Санки в extraReducers. Т.е. обычные reducers для обычного изменения состояния, а extraReducers для asyncThunk.
У каждого asyncThunk есть 3 состояния: 
pending (запрос еще идет), fullfilled (запрос выполнен успешно), rejected (запрос выполнен с ошибкой).
Можно их все обработать в extraReducers, через builder.addCase.
Для каждого case типы action.payload подтягиваются такие, как были указаны в санках (для error свой, для fulfilled свой).
Создали компонент Text в shared слое. Он предназначен для работы с текстовыми данными, для стандартизации.
Где-то будут заголовки, спаны, параграфы и т.п., и это надо одинаково отрисовывать.
В идеале разработать такую библиотеку компонентов, при которой css будут писаться по-минимуму. 
Т.е. все потребности должна удовлетворять библиотека.
В санке авторизации так же делаем сохранение в localStorage. В слайсе добавляем initAuthData, который будет брать данные
из localStorage и сетать их в стор. Сам метод initAuthData будем запускать в корне приложения.

Подведение итога:
У нас есть entity User, которая отвечает за то, авторизован пользователь или нет. 
Внутри себя она хранит данные об этом пользователе.
Для формы авторизации сделана отдельная фича, которая изолирует внутри себя данные формы, ошибки, индикацию загрузки.
Получилось так, что в фиче в publicApi наружу выдается только компонент модалки, тип и редьюсер.
Не используются какие-то внутренние штуки как селекторы, asyncThunk, экшены 
и не создаётся лишних связей (всзаимодействий) между модулями. К такому необходимо стремиться.
В фиче используется нижестоящий слой entity, так и нужно делать в FSD.

Чтоб фича была в сторибуке, нужно подключить провайдер редакса (shared/config/storybook/StoreDecorator);
Так же в конфиг для сборки сторибука нужно определить IS_DEV переменную
config.plugins.push(new DefinePlugin({ __IS_DEV__: true })); 
Всегда true, т.к. storybook используется только в режиме разработки. Кто-то использует и для прода, но тут не так.
Для i18n так же сделан декоратор TranslationDecorator
в config/storybook/preview.ts добавлен
Если скриншотные тесты ломаются, нужно запускать report и смотреть что там

35. Оптимизация бандла. Асинхронные редьюсеры.
Для оптимизации бандла для прод сборки, вынесли в buildPlugins.ts плагин BundleAnalyzerPlugin из условия isDev.
запустим yarn build:prod (появится ссылка в терминале)
В parsed режиме весит 304.84кб, в gzipped 94.26кб

Для начала сделали AsyncLoginForm (асинхронный компонент формы LoginForm), обернув в Suspence рендерим его в модалке.
При проверке в девтулзах (network) видно как подгружается дополнительный чанк при открытии модалки.
Бандл main уменьшился на 2кб

Разница не большая, т.к. компонент маленький. Плюс это прод сборка. Для дев сборки разница может быть уже в 20кб.
Так же есть ньюанс, что компонент асинхронный. Но редьюсер с экшенами - нет (т.к. они подключаются по итогу к корневому редьюсеру),
поэтому они уходят в главный бандл.
В редьюсерах, как правило, достаточно много строк кода и можно неплохо урезать главный бандл,
если подгружать его асинхронно.
100 строк кода примерно равно 3кб в прод-сборке
Можно загуглить "redux code splitting" и найти инфу как асинхронно подгружать редаксовский код.
Можно использовать store.injectReducer/replaceReducer.
Создали рядом файл reducerManager.ts (там будет логика для асинхронного добавления или удаления редьюсеров из стора).
Он используется в связке с асинхронными компонентами, чтобы код редьюсера так же не попадал в main чанк.
Подключили его store.reducerManager в store.ts. Убрали там LoginForm редьюсер (он будет асинхронно подгружаться).
Обязательно передать в поле reducer: reducerManager.reduce, чтоб передать новые редьюсеры
В LoginForm.tsx используем стор, const store = useStore(); через хук из redux
в useEffect при монтировании компонента store.reducerManager.add('loginForm', loginReducer);
Из экспорта модуля убрали экспорт наружу (т.е. он используется самим модулем и асинхронно подгрузится).
При размонтировании компонента нужно так же убрать его store.reducerManager.remove('loginForm');
Вынесли в отдельный компонент src/shared/lib/components/DynamicModuleLoader/DynamicModuleLoader.tsx
Им нужно будет оборачивать асинхронные (lazy) компоненты
логику по асинхронному добавлению редьюсера (не в shared/ui т.к. пол сути рендера разметки интерфейса нет).
Вернули BundleAnalyzer только в dev режиме.
Вообще есть отдельные библиотеки для Lazy подгрузки редьюсеров, но тут реализовано свое решение.

Падали скриншотные тесты, т.к. в сторибуке не отображаются ошибки неверных кредов для авторизации.
Т.к. при инициализации не определяется асинхронный редьюсер.
Добавили в StoreProvider передачу asyncReducers, которые передаются в createReduxStore.

36. Тестирование фичи authByUsername. TestAsyncThunk.
Написание простых тестов на селектоны, на слайс и actionCreator.

Сначала написали тесты на селекторы (getLoginUsername, getLoginPassword и т.д.).

Так же на asyncThunk loginByUsername. Там нужно мокать запросы (jest.mock('axios') и потом использовать модуль axios).
jest для замоканных модулей добавляет функции (например axios.post.mockReturnValue()), которые позволяют замокать какое-то
возвращаемое значение. Но TS по-умолчанию эти типы не подхватывает, поэтому можно воспользоваться конструкцией:
const mockedAxios = jest.mocked(axios, true).
1 аргумент это модуль, который хотим замокать. 
2 (true) - это флаг с глубоким моком (т.е. мокаем не только сам модуль, но и внутренние поля).
asyncThunk это actionCreator, который по итогу вызова возвращает action.
Как отрабатывают диспатчи в asyncThunk:
- 1 вызов диспатча отрабатывает когда вызван сам экшен loginByUsername
- 2 вызов диспатча - когда вызывается экшен setAuthData с передачей response.data отработанного запроса
- 3 вызов диспатча - когда происходит fullfilled, т.е. когда экшен успешно выполняется (после return в конце).
В случае ошибки диспатч вызовется 2 раза (т.к. не будет setAuthData).
Эта логика для тестирования asyncThunk будет переиспользоваться, чтобы не дублировать.
Вынесли её в shared/lib/tests/TestAsyncThunk/TestAsyncThunk.ts
Это класс, в котором будет изолирована эта логика.

Так же пишется тест для loginSlice.
Тестировать isLoading или error избыточно, т.к. обычно в слайсах тестируют присвоения (в actionCreator такие тесты уже написаны).

37. Страница профиля. useAppDispatch. Оптимизация ререндеров и мемоизация.
Хук useDispatch не возвращает все типы результата вызова диспатча.
Что бы это исправить можно загуглить https://redux-toolkit.js.org/usage/usage-with-typescript.
Создать тип (AppDispatch в store.ts) и хук useAppDispatch (в shared/lib/hooks).
Например подтянутся типы для result.meta.requestStatus, можно будет делать проверку по нему.
В LoginForm по результату useAppDispatch (fulfilled) сделали закрытие модалки в onLoginClick (запуск onClose модалки).
Далее расширили структуру данных в db.json для json-server.
Создали pages/ProfilePage. 
(Для lazy импортов нужно чтобы компонент экспортировался по-дефолту, поэтому не page компоненты так экспортятся).
Добавили конфиг в Sidebar, чтобы на основании него отрисовывались новые табы.
Для начала сделали SidebarItem, он будет принимать item. Тип этого item будет определяться в директории model.
Для иконок в svg файле удалялись fill, чтобы можно было управлять цветом извне.

Дебажили мемоизацию. Вынесли мапанный массив с разметкой в useMemo.
В девтулзах браузера открыли вкладку components (реактовский девтулз).
Нажали шестерёнку и выбрали галочку на "Highlight updates when components render."

Так будут подсвечиваться обновления (рендер компонента), в виде обводки элемента в UI.

Ререндер компонента в 3 случаях:
1) Изменилось состояние
2) Изменился props
3) Ререндер родителя (этот пункт можно предотвратить мемоизацией при помощи memo)

При оборачивании компонента memo, он будет сравнивать пропсы.
Если пропсы не изменились при ререндере родителя, то ререндер компонента не произойдёт.
ThemeSwitcher и LangSwitcher так же обернули в memo, чтобы они не ререндерились лишний раз.

Оборачивание в memo - хорошая привычка и почти 90% компонентов необходимо оборачивать в memo.
Пробежались по компонентам и обернули в memo (Sidebar, Navbar).

Какие компоненты оборачивать в memo не стоит:
1) Компоненты у которых есть children, т.к. в большинстве случаев children будет меняться 
и перерисовку компонента это не предотвратит (если конечно это не простая структура в виде строки и прочего примитива)/
Т.е. например Button (где children это строка) имеет смысл мемоизировать, а Modal (где children всегда компоненты) - нет.
2) Когда пропсы не мемоизированы (колбеки не в useCallback, сложные структуры данных типа объекта не в useMemo)

Когда перерисовывается интерфейс, задействуется процессор, видеокарта. А memo всего-лишь тратит какое-то количество памяти.
Сейчас памяти у всех оч много и забить какой-то процент браузера достаточно сложно, нужно хранить миллионы замемоизированных компонентов.
А вот вычислительные мощности (процессор, видеокарту) нужно по-хорошему беречь, чтобы все работало быстро.

Далее создали entities/Profile.

38. Инстанс API, ApiUrl, thunkAPI.extra.
Нужно создать настройку axios в обном месте, чтобы в разных местах не настраивать его одинакого, с одним и тем же доменом и т.п.
Создали shared/api/api.ts в котором создали инстанс axios.
$ перед названием переменной инстанса axios ставится, чтобы как-то его отличать.
Внутри thunk (например в loginByUsername.ts) нужно получить доступ до инстанса, который сделали.
Это можно делать обычным импортом/экспортом, но мы использовали другой способ.
Есть агрумент thunkAPI.extra, в которой можно положить любые вспомогательные функции, данные.
В thunkAPI.extra мы и поместили инстанс апи (в файле store.ts в конфигурации рутового стора указывается поле middleware).
В redux-toolkit уже есть по-дефолту набор мидлвар (thunk, с помощью которого можно удобно работать с изменениями стейта).
Когда поместим в extra инстанс апи, можно будет в санках делать запросы extra.api.post.
Так же указан в инстансе baseURL, и его можно в запросах уже не писать.
Так же можно navigate (из useNafigate from react-router-dom) поместить в extra.
Далее нужна настройка типизации extra, т.к. ts не подхватывает типы в инстансе санки.
Описание типов в app/providers/StoreProvider/config/StateSchema.ts.
Вынесли для инстанса апи baseUrl, (можно исходя из __IS_DEV__, но мы создали новую глобал переменную __API__).
Переменная __API__ будет задаваться на этапе сборки приложения (config/builds/).
Добавили apiUrl в типы BuildEnv и BuildOptions (чтобы можно было извне это поле задавать).
B при создании нового инстанса new webpack.DefinePlugin добавили __API__.
Примерно то же самое для сторибука (__API__: '', в config.plugins.push).
И в jest.config.ts определил глобально __API__: ''
Так же в app/types/global.d.ts declare const __API__: string;
И в eslintrc.js __API__: true, (Чтобы он не ругался).
Инициализация самого значения в webpack.config.ts (const apiUrl = env.apiUrl ?? 'http://localhost:8000').
Т.е. либо получаем это значение из переменной окружения, либо по-умолчанию локалхост.

39. Модуль профиля. Фетчинг данных. TS strict mode.
Продолжили реализацию модуля профиля. Сделаем servises (асинхронные экшены).
Сделали extraReducers в profileSlice с сохранением фетченных данных в стор.
Сделали селекторы, для чтения этих данных в компонентах.
(state: StateSchema) => state.profile.data.first. Тут есть момент, поле дата опциональное.
Но при попытке получить вложенное поле из data, ts не ругается, т.е. может получиться, что у undefined будет запрашиваться поле.
В таком случае приложение упадет с ошибкой. Это связано с тем, что не стоит StrictMode в typescript.
Включили strict mode и правили ошибки. В tsconfig.json поле "strict": true.
Использовать ts без строгого режима не имеет смысла. Нужно обязательно его использовать на проектах.
Чтобы такие вот ошибки не пропускать.
TS ошибки на рантайм не влияют, поэтому фронт не падает из-за них.
Так же добавили в entities/Profile/ui/ProfileCard, которую отрендерили в ProfilePage.

40. Починка типов и проекта после TS strict mode. ThunkConfig.
Интересные моменты:
ref может быть типа MutableRefObject (можно менять ref.current) и просто RefObject (only reading ref.current).
Сделали глобальный тип DeepPartial в global.d.ts.
Есть свойство "no-undef" в eslint. Это свойство предотвращает использование каких-то глобальных переменных, типов.
Отключили это правило, т.к. оно в основном используется с var, а мы его не используем.
После включения strict mode, он распространяется не только на файлы разработки, но и на конфиги.

41. Модуль профиля. Avatar. Редактирование и сохранение. Приватные роуты.
Сделали ProfileCard переиспользуемым, путем передачи данных в props, а не используя внутри селекторы.
Вообще слой entities редко когда обладает своим состоянием. 
Чаще всего это переиспользуемые компоненты, куски логики, запросы к серверу, типы и т.п.
Поэтому entities/Profile/ui/ProfileCard будет чисто визуальным, а логику вынесем в pages.
В профиле кнопку "Редактировать" поместили на уровне page.
Т.е. где-то на странице мы хотим редактировать, а не в карточке. По этому это функционал страницы.
Создали pages/ProfilePage/ui/ProfilePageHeader.
Далее реализовали функционал, чтобы редактировать данные в полях можно было только после нажатия на кнопку "редактировать".
За это будет отвечать поле readonly (добавили в props Input - readonly).
В слайсе сделали помимо data свойство form, чтоб там сохранять вводимые данные и отделить их от основных.
Реализовали санку сохранения данных на сервере. В ней впервые используем getState для получения данных для отправки.
На текущий момент getState() возвращала unknown (т.е. она не знала какого типа данные она будет возвращать).
Указывается тип в джинерике ThunkConfig.state (добавили в тип ThunkConfig state: StateSchema).
В компонентах для получения стэйта мы используем хук useSelector, а внутри asyncThunk мы используем getState.
Так же будет отправляться put запрос (т.к. на обновление данных). В json-server/db.json они тоже изменятся.
Создали shared/ui/Select.
Так же вынесли в entities/Currency сущность валюты. Она может быть в создании поста, в кошельке, в профиле пользователя.
Можно воспользоваться средствами переноса webstorm по переносу enum из 1 файла в другой, чтоб не править везде импорты.
Правой кнопкой по enum (refactor -> move). Там же в ui будет селектор чисто для currency (удобно переиспользовать).
То же самое для Country (в entities).
Так же, если разлогиниться, но в карточке профиля будет ошибка (т.к. контент доступен только авторизованным пользователям).
Для этого реализован PrivateRoute. Пока сделали по колхозному, в конфиг добавили поле authOnly, по условию которого рендер.

42. Валидация профиля. Коды ошибок.
Создали entities/profile/model/services/validateProfileData.
Можно сделать простую функцию, либо asyncThunk, которая берет данные из стейта.
Мы пойдем по 1 пути, когда функция принимает профиль как аргумент.
Создали enum типы валидационных ошибок (в том числе с ошибкой от сервера).
Применили проверку в санке updateProfileData, перед совершением запроса. Если ошибки есть, то rejectWithValue.
В ProfilePage получаем ошибки из селектора, мапим массив в компонентах Text.
В profileSlice сделали созранение/удаление validateErrors, где это нужно.
Добавили словарь с отображениями ошибок с переводом (по коду);

43. Глобальная переменная __PROJECT__. Тесты на модуль профиля.
Содали сторис для ProfileCard.
Для тестирования или отображения в стрибуке изображений, лучше использовать локальный asset, чтобы не грузить её с сервера.
Поместили такие картинки в shared/assets/tests.
В сторисах для profilePage в storeDecorator передали form данные.
Там была ошибка запроса (по-хорошему в сторибуке не должно быть спама запросами, нужно подтягивать моканные данные).
Есть разные способы предотвращения запросов в компонентах (в useEffect).
Мы использовали один из способов. Разделили среды, в которых исполняется код.
Для buildPlugins расширили входные аргументы, передали project: 'storybook' | 'frontend' | 'jest'.
Для всех трёх сред своя конфигурация. Аргумент project для каждой среды можно переопределить.
Сначала в webpack.config.ts передали в buildWebpackConfig аргумент project: 'frontend' (т.е. это основная среда, в которой ведётся разработка).
В файле buildPlugins определили новую глобальную переменную __PROJECT__: JSON.stringify(project).
То же самое сделали для тестовой среды jest.config.ts (в globals __PROJECT__: 'jest').
То же самое для конфига storybook в файле webpack.config.ts (__PROJECT__: JSON.stringify('storybook')).
Теперь определены 3 среды, в зависимости от которых можно реализовывать тот или иной функционал.
Так же в eslint.rc добавили __PROJECT__: true, чтобы линтер не ругался.
Так же в глобальную декларацию global.d.ts нужно так же добавить глобальную переменную __PROJECT__, чтоб не ругался ts.
При этом не просто string (declare const __PROJECT__: 'storybook' | 'frontend' | 'jest').
Если добавится еще одна среда, можно в типах просто добавить её в 2-х местах.
В ProfilePage в useEffect делается запрос dispatch(fetchProfileData()) только если __PROJECT__ !== 'storybook'.
После этого в сторибуке запрос не отправляется, данные подтягиваются моканные, прописанные в сторисах ProfileCard.

Далее писали юнит тесты на ProfileCard.
Для начала селекторы, потом сервисы.
В updateProfileData тестируется санка, в которую данные не передаются в виде аргумента, а они извлекаются из апи redux - getState.
Чтобы проинициализировать стэйт и функция getState внутри санки вернула данные,
в конструктор класса TestAsyncThunk сделали возможность передачи необязательного аргумента state.
this.getState = jest.fn(() => state as StateSchema);
В updateProfileData.test передадим initialState.
Потом написали тесты на profileSlice.
На реальных проектах редьюсеры редко покрываются тестами, только если там есть условия, циклы, какая-то сложная логика.
Мы написали чисто ради тренеровки.

44. Color pallete. Внедрение новой третьей темы.
Использовался ресурс https://mobilepalette.colorion.co/.
Там можно подобрать цвета таким образом, чтобы было 2 темы (основная и inverted).
Основной паттерн это: есть несколько цветов (основной и второстепенный для шрифтов, заднего фона).
С помощью него подобрали новую цветовую палитру.
Добавили файл orange.scss с новыми цветами.
импортировали этот файл в index.scss.
Изменили useTheme, добавили switch case для переключения тем.
Так можно технически добавлять неограниченное количество новых тем.

45. npm concurrently. File templates.
Небольшое упрощение разработки.
Фронт и dev-server запускались отдельно 2-мя командами (start и start:dev:server).
Нужно чтобы была команда, которая в дев режиме одновременно бы запускала сервер и фронт.
Для этого понадобился пакет concurrently.
Работает просто, concurrently и через пробел несколько команд, запускающих скрипт.

Так же, каждый раз приходится создавать папку. 
Потом нужно создавать одноименный компонент, одноименные модульные стили, тесты, сторисы и т.д.
В webstorm, settings => editor => file and code templates. Можно создать новый шаблон, к нему добавлять дочерние шаблоны.
Название файла определяется через переменную ${NAME} (в том числе в названии файла).
Для создания шаблона, правой кнопкой мыши по папке, new, <Название созданного template> (будет в списке опций).

46. React refresh plugin. build babel loader.
Не работал refresh plugin.
Для примера, в корневой div можно добавить инлайновый стиль (color: red),
но в режиме реального времени он не обновляется, а только при перезагрузки страницы.
Хотя подключался HotModuleReplacementPlugin (в файле buildPlugin),
и он должен обеспечивать своевременное обновление некоторых моментов (которые должны работать, например изменение стилей).
Взяли плагин отсюда https://github.com/pmmmwh/react-refresh-webpack-plugin.
В buildLoaders.ts для babel-loader добавили плагин в dev режиме.
В buildPlugins.ts в дев режиме добавили react-refresh-plugin.
Создали loaders/buildBabelLoader.ts, чтоб вынести бута плагины babel.
В результате, при изменении стилей на элементе, он обновляется в браузере сразу, без перезагрузки страницы.
Что-то он может обновлять, что-то нет. Но чаще всего быстрое обновление именно для верстки (стили, надписи).
Это немного ускоряет разработку.

47. Router v6 private protectеd routes. Защищенные маршруты.
Несколько уроков назад был реалирован роут, защищенный (только для авторизованного пользователя).
Если на него зайти, то тут 404 роут, это нарушает пользовательский опыт (ux).
Пользователю не всегда понятно, почему роут иногда доступен, а иногда 404.
По-хорошему для таких роутов надо делать редирект.
Создали компонент RequireAuth, который (как мидлвар) проверяет, если isAuth то рендерит children, иначе редирект на main.
Обернули этим компонентом роуты, по условию authOnly.
Так же был ньюанс, что AppRouter инициализировался раньше, чем мы получали данные о пользователе.
Получалось, что на момент когда 1 раз отрендерился AppRouter, мы еще не авторизованы.
Добавили в схему User флаг _inited, который показывает, что пользователь проинициализирован (в редьюсере initAuthData).
В корневом App.tsx отрисовываем Router только если _inited === true (т.е. данные о пользователе получены и мы точно знаем авторизован он или нет).

48. ArticlesPage и ArticleDetailsPage. Декомпозиция. Сущности. Webpack publicPath.
Создали 2 page (ArticlesPage - список, ArticleDetailsPage - одна статья).
Роуты /articles и /articles/:id. (Множественное число для еденичной сущности лучше масштабируется и следует правилам rest).
При переходе на роут /articles/123 была проблема, что браузер пытается запросить чанк,
т.е. в строке запроса появляется лишний articles (должен запросить из корня, а запрашивает из articles, а у нас такой папки нет).
Т.е. такие статические файлы по факту запрашиваются из папки build, в которую мы делаем сборку. 
Просто в dev режиме эта папка не создается, эти файлы все хранятся в памяти (описания в buildWebpackConfig.ts в поле output).
Нужно добавить publicPath в output

## Пояснение от себя (что нагуглил):
При переходе на роут /articles/123, браузер интерпретирует путь /articles как базовую директорию для запросов к статическим файлам.
Поэтому, вместо того чтобы запросить файл main.a20f058c4f8f5bf80443.js из корня (/main.a20f058c4f8f5bf80443.js),
он делает запрос по неправильному пути: /articles/main.a20f058c4f8f5bf80443.js.
Это происходит из-за особенностей работы браузера с относительными путями к статическим ресурсам, 
когда путь для запросов определяется текущим маршрутом.

В режиме разработки (dev-сервер Webpack):
Статические файлы не хранятся на диске. Они предоставляются из памяти (in-memory) dev-сервера.
Dev-сервер настроен так, чтобы корректно обрабатывать любые запросы и возвращать соответствующие файлы,
даже если путь содержит дополнительные сегменты (например, /articles/123).

В режиме production (после сборки):
Статические файлы сохраняются в папке build, и сервер должен их предоставлять из этой папки.
Сервер обычно обслуживает файлы строго в соответствии с указанным путём,
поэтому запросы по неверным путям (например, /articles/main.a20f058c4f8f5bf80443.js) приводят к ошибке 404.

49. Entity article, async thunk, slices. Блоки. Skeleton loader.
Расширили данные в json-server/db.js
Реализация статей будет примерно как на habr. Картинки, блоки с текстами, блоки с кодом, темы статьи.
Создали новую ентити Article.
В entities/articleDetails не будет делать отдельную папку для каждого селектора, все делается в одном файле.
Т.к. как правило селекторы максимально простые.
Внедрили Skeleton для нотификации разгрузки в шаблонах контента.
В интернете полно гайдов как сверстать скелетон (css), поэтому время на него не тратили.

50. Страница статьи. Блочная структура. Компонент Code. Копирование.
Тут делали отображение самой статья, её составных блоков.
Добавили size enum для Text.
Добавили компонент обертку в shared/ui/Icon, который задает для всех иконок в приложении цвет (fill), исходя из темы.
Добавили компонент shared/ui/Code (компонент отвечающий за стилизацию текста в виде кода).
В html5 есть специальный тег code для работы с кодом, но нужно обернуть в pre,
который позволяет сохранить все пробелы, переносы и т.п., чтоб текст выглядел как код.

51. Модуль комментариев. Нормализация данных. EntityAdapter.
В статьях реализован функционал комментариев от других пользователей.
Коммент представляет из себя Entity, а создание комментария - Feature.
Важно реализовать комментарий, чтоб он не был привязан конкретно к статье.
Т.к., если мы например из блога захотим сделать интернет магазин и захотим оставлять комменты над товаром, профилем пользователей.
То нужно сделать архитектуру и структуру так, чтобы комменты были переиспользуемыми сущностями.
По организации кода, т.к. комменты будут переиспольщованы, они не будут как articleDetails принимать id и делать внутри запрос и чтение из стора.
Коммент будет принимать данные коммента из пропсов.
Сами комментарии от страницы статьи (слайс стора), будет храниться на уровне page/ArticleDetails.
Так же можно было бы создать отдельную фичу (ArticleCommentList) и внутри неё изолировать стейт, запросы, переиспользовать сущность.
Нормализация данных - концепция (redux-toolkit entity adapter).
Проблематика: пример с 4 списками товаров (все, измененные, черновик, на модерации).
При изменении состояния одной сущности из списка "все", она улетает в "измененные" и т.д.
Это та же сушность по сути. Дублировать её для всех для нескольких списков это избыточно,
плюс необходимо, чтобы все эти дублируемые данные были одинаковыми (реально частая проблема, которая возникает на практике).
Другой пример, у нас есть массив объектов и нам надо изменить одно из полей объекта.
Чтобы это сделать, нужно проитерироваться по всему массиву, найти нужный объект, заменить у него поле, а во всех остальных случаях возвращается старый объект.
Здесь приходит на помощь нормализация. Тут нужно относитья к данным на клиенте примерно так же, как к данным, хранящимся в БД на сервере.
При нормализации у объектов не хранятся вложенные объекты, хранятся только идентификаторы (foreign_key как в БД).
Так мы избавляемся от дублирования данных и плюс, при изменении в одном месте, изменения произойдут везде, где используется ссылка-id.
Так же данные хранятся не в массиве, а в объекте, где ключ это id. Уменьшается константное время допуска к объекту.
В redux-tooklit есть обстракция, с помощью которой можно делать нормализацию с минимумом строк кода.
С помощью createEntityAdapter, создается адаптер, с помощью которого реализуется большое количество функционала.
Он гонерит набор бозовых экшенов (CRUD-functions), предназначенных для работы с коллекциями, Набор базовых селекторов.
Данные достаем как useSelector(getArticleComments.selectAll). Так же есть другие полезные методы.
Теперь нет необходимости писать руками селекторы.
Но для кастомных, типа isLoading и error нужно писать селекторы.
Т.к. находится на уровне pages, но может быть несколько селекторов и нужно создавать вложенные подпапки (selctors/comments/...).
Конструкция запроса в useEffect без учета сторибука начала часто использоваться, вынесли в кастомный хук.
shared/lib/hooks/useInitialEffect.
В extraReducers в fulfilled можно использовать Adapter.setAll(state, action.payload);
Этот метод адаптера сам нормализует список (сформирует ids, entities и т.п.).

52. Профили пользователей. Фича addCommentForm.
Хочется открывать профиль другого пользователя по роуту profile/id.
Расширили бд, сделали profile как массив объектов профилей.
Создали новую фичу addCommentForm для добавления комментариев.
Из public api фичи (index.ts) наружу селекторы и редьюсеры не уходят, только тип схемы и компонент (асинхронный).
К этому в идеале необходимо стремиться.
При отправке post запроса на добавление нового комментария UI не обновлялся.
Сделали после успешной отправки комментария очистку инпута dispatch(addCommentFormActions.setText('')).
Так же нужно добавить в UI новый коммент. Можно либо сделать запрос за новыми данными, либо добавить локально в стейт (и то и то норм).
сделали запрос dispatch(fetchCommentsByArticleId(article.id)).
Реализация получилась не идеальна, мы хотели реализовать комментарии максимально отвязанными от статьи, чтоб их можно было переиспользовать.
А мы сделали отправку запроса с articleId, но хотели в будущем переиспользовать для комментов других сущностей (товаров, профилей).
Добавили сервис addCommentForArticle для articleDetailsPage.
В AddCommentForm в пропсах передали onSendComment, тем самым сделав его переиспользуемым.
Старый сервис sendComment удалили, т.к. заюзали новый addCommentForArticle.
Так же text там передается аргументом (а не из стора). Очистка инпута так же будет из вне.
Так же появилась возможность переходить в профили комментаторов, но их можно редактировать все.
Сделали так, чтобы редактировать можно было только свой.
Добавили проверку authData.id === profileData.id.
Нужно будет потом дописать тесты на селекторы, санки и т.д.

53. Апгрейд сайдбара. Селекторы.
Сейчас при попытке перейти в профиль формируется роут /profile/ и не загружается свой профиль.
Решили формировать массив ссылок для сайдбара в селекторе редакса, подставлять там id текущего пользователя.
Воспользовались createSelector из редакса, чтобы переиспользовать селектор и создать на основе него другой для сайдбара.

54. Список статей. useHover. Переключение вида.
Сделали entities/Article/ArticleList / ArticleListItem.
Прокидывать статьи в ArticleList будет извне в пропсах, т.к. статьи будут в разных местах (список рекомендаций внутри просмотра статьи).
Реализовали shared/ui/Card.
Реализовали shared/lib/hooks/useHover для ховер эффекта с помощью js.

55. Статьи. EntityAdapter, thunks, slices. View selector.
Наполнили pages/articlesPage/model кодовой базой (редакс, фетчинг данных).
Добавили ArticleViewSelector в entity/Article. Но можно было и в фичу (там было бы лучше, потом отрефакторим), и в page.
Сделали сохранение выбранного значения view в localStorage, чтобы пользователь после перезагрузки страницы заного не менял его.
В LocalStorage.ts сделали еще одну константу.

56. Пагинация. Page. Бесконечная лента. Observer API. useInfiniteScroll.
Накидали побольше статей в бд.
Посмотреть как работает пагинация можно посмотреть в доке json-server#paginate (2 квери-параметра: номер страницы и лимит сущностей на 1 стр).
В ArticlePageSchema добавили поля page, limit, hasMore. Добавили передагу аргументов в санку fetchArticlesList.
limit будет разный (если view.big - то 4, иначе 9).
Реализовали механизм, который при скроле будет подгружать порции.
Элемент page-wrapper удалили, т.к. она противоречила парадигме модульности. 
Создали компонент для страниц, который будет их оборачивать и содержать внутри себя какую-то логику. Пока что в shared слой.
Потом обернули все pages в компонент Page (вместо div).
В page компонент обертка будет не div, а section (семантически более правильно).
По поводу семантики, зачем она нужна? Когда на страницу заходят роботы, люди с ограниченными возможностями,
Страница парсится на семантические куски.
Для человека с ограниченными возможностями робот читает и интерпретирует более правильно все что на странице находится.
Т.е. если будет div с ролью кнопки, для человека с плохим зрением или робота это будет неочевидно.
Для Navbar сделали header тег. Для Sidebar - menu.
В компоненте Page мы будем следить на скролом и подгружать порцию.
Создали хук в shared/lib/hooks/useInfinityScroll (который будет использовать IntersectionObserver).
Intersection api позволяет наблюдать за появлением элементов и реализовывать lazy loading (изображений), бесконечные эвенты и т.п.
Заюзали этот хук в Page (вообще можно в любом его юзать). wrapperRef на section. triggerRef на div внизу страницы.
Добавили передачу в пропсах Page необязательный колбек onScrollEnd, который передается как колбек в хук.
После проверки работы подгрузки данных на скролл был бесконечный спам запросами.
В ArticlesList убрали условный рендер скелетонов на isLoading (добавили рендер в конец элементов).
Так же в articlesPageSlice для fetchArticlesList.fulfilled использовался метод setAll (для нормализации).
Его заменили на addMany (чтобы полностью не перезатирался весь массив сущностей, а новые добавлялись в конец).
Так же добавили логику state.hasMore = action.payload.length > 0
(т.е. если в порции хоть одна сущность, значит данные еще есть, иначе следующая порция прилетит пустая).
Так же проверка на hasMore в onScrollEnd.
Такую логику проверки нужно выносить из компонентов в редьюсеры либо экшены. Создали services/fetchNextArticlesPage.
Т.е. этой слой бизнес логики, а компонент это отображение. Там мы дергаем при помощи диспатча экшены, в которых бизнес-логика.
Так же мы можем написать тесты на этот екшен, проверить что он запускается если уже есть 1 порция данных и hasMore.
Так же при переходе на другой роут падала ошибка Failed to execute 'unobserve' on 'IntersectionObserver'.
Это было из-за того что в хуке useInfinityScroll observer.unobserve === undefined.
wrapperRef и triggerRef приходят извне и могут затереться. А отписываемся от события внутри useEffect.

57. Инициализация страницы. Чиним монтирование Store. Mounted reducers.
Тут был рефакторинг.
При переходах на страницы зачищается история redux-devtools.
Это из-за того, что происходил новый рендер компонента StoreProvider, а в нем происходит новая инициализация стора.
Ререндер происходил из-за передачи функции navigate (из react-router).
Поэтому убрали его передачу в StoreProvider, нужно будет придумать другой способ его передачи.
Убрали removeAfterUnmount у DynamicModuleLoader в ArticlesPage, т.к. есть переход по статье, её чтение и возвращение назад к сохраненному списку.
Но при этом, при возврате на страницу списка снова отработал @init и снова произошел fetchList последней порции.

Если подытожить. ReduxProvider должен рендериться один раз при инициализации
(не должно быть ререндеров при совершении каких-то действий в приложении типа переходов на другую страницу).
Если программно не удаляется слайс с данными, то данные по нему должны сохраняться без повторной инициализации.
Добавили поле _inited в ArticlesPageSchema (с нижним подчеркиванием, т.к. предполагаем что поле неизменяемое).
Потом в articlesPageSlice в экшене initState сетаем его в true.
И в useInitialEffect в ArticlesPage добавляем проверку fetch только если !inited
Появилось условие, несколько диспатчей, поэтому вынесли логику из компонента в новую санку initArticlesPage.
TODO - написать тесты на initArticlesPage (проверить что в инициализированном стейте экшены не отрабатывают, а в неинициализированном наоборот отрабатывают).
Так же была проблема что несколько раз глобально монтируется редьюсер (глоабльно это ни на что не влияет, но не очень хорошо).
В DynamicModuleLoader в useEffect где происходит монрирование редьюсеров нужно проверять, вмонтирован он уже или еще нет.
В ReducerManager добавили еще одно поле mountedReducers: Record<StateSchemaKey, boolean>.
Если значение true, значит редьюсер с данным ключем уже монтирован, иначе нет (или был удален).
Сделали кастомный тип OptionalRecord в global.d.ts (т.к. в обычном Record все ключи обязательные должны быть, а в кастомном нет).
Т.е. сделали так mountedReducers: OptionalRecord<StateSchemaKey, boolean>,
потому что не все редьюсеры обязательные (какие-то монтируем, какие-то нет).
Ну и дальнейшем этот тип может пригодиться.
Изменили на getMountedReducers
В reducerManager добавили поле getMountedReducers: () => mountedRedusers,
Так же есть функция getReducerMap, которую можно было использовать без создания getMountedReducers (TODO).
Она возвращает список редьюсеров, и там можно было бы смотреть, вмонтирован ли редьюсер или нет.
В Add кейса сделали mountedRedusers[key] = true, в remove - mountedRedusers[key] = false.
Внутри useEffect DynamicModuleLoader достали const mountedReducers = store.reducerManager.getMountedReducers().
Потом внутри цикла 

58. Троттлинг. useThrottle. UI state. Сохранение позиции скролла.
Пофиксили ворнинг uncontrolled input на странице статьи (туда попадал undefined и он становится неуправляемым).
В селекторе добавили state?.addCommentForm?.text ?? ''.
По части сохранения позиции скролла, хотелось бы, чтобы при просмотре страницы статьи и возвращении обратно на страницу списка,
сохранялась бы позиция из которой был переход, чтоб заного не скролить.
Перенесли shared/ui/Page в widgets/Page (по логике он не подходит для shared слоя).
Там в нем будет логика по восстановлению скрола, логика бесконечной ленты (это подходит под уровень виджет, наравне с навбаром например).
Создали новую фичу features/UI, в ней логика по остановлению и сохранению позиции скрола.
Предполагалось что в фиче UI будет еще какой-то функционал по UI.
TODO - вынести эту логику на уровень виджета (назвать SaveScroll)
Создали тип ScrollSchema = Record<string, number>, ключ это строка со страницей, а number - значение в пикселях положения от верхнего края.
Наверняка есть готовые решения по сохранения скрола, но мы сделали свое.
Чтоб можно было посмотреть как работать с тротлингом, в каких ситуациях его можно использовать.
Сам ui reducer будет синхронным.
Сохраняется значение скрола в компоненте Page в onScroll (event.currentTarget.scrollTop), сохраняем это значение в store.
path берем из useLocation внутри Page.
Можно опционально сохранять позиции для некоторых страниц, например передавать пропс isSetScroll
Потом в компоненте Page в useInitialEffect делаем wrapperRef.current.scrollTop = scrollPosition (данные из селектора).
Но решение не идеальное. В момент скролов отрабатывает много экшенов, спамится история в redux-devtools, нагрузка на производительность.
Поэтому воспользуемся механизмом throlle, который будет позволять использовать событие только в определенный промежуток времени.
Например сохранять скрол только 1 раз в секунду.
Создали shared/lib/hooks/useThrottle.

59. Фильтры. Сортировка. Поиск. Tabs. useDebounce.
Сделали triggerRef (блок при видимости которого срабатывает onScroll) побольше (в высоту), чтоб всегда отрабатывал.
Добавили в стейт фильтры, которые отвечают за сортировку, поиск и т.д. (order, sort, search).
В документации json-server можно найти правила сортировки и поиска.
Сделали shared/types/index.ts (т.к. проект не большой, но по-хорошему сделать отдельный файлик (sort или order) и добавить туда).
По-хорошему выносить надо было в features/ArticleSort (потом отрефакторим).
ArticlesPageFilters можно было вынести в отдельную фичу, но т.к. она используется только на одной странице, то
она находится в page рядом.
Надо стремиться к тому, чтобы страницы были набором каких-то компонентов (фичей, виджетов ...).
Создали ArticleSortSelector.
В компоненте ArticlesPageFilters в onChange для полей сделали запросы.
Можно было и в useEffect и передать в зависимости фильтры, но по-хорошему от сайд эффектов лучше избавляться, чтобы не было лишних зависимостей.
В extraReducers для fetchArticlesList.fulfilled, добавили проверку
if (action.meta.arg.replace) articlesAdapter.setAll(state, action.payload);
else articlesAdapter.addMany(state, action.payload);
Т.к. при фильтрации или сортировке не нужно добавлять порции новых данных к старым, нужно заменять новыми отфильтрованными данными
и сбрасывать page на 1.
В fetchArticlesList.pending так же можно сделать
if (action.meta.arg.replace) articlesAdapter.removeAll(state) чтобы очистить старые данные на этапе pending новых.
Есть ньюанс, что на каждое изменение в инпуте search отправляется запрос.
Т.е. введя 10 символов отправляется 10 запросов. Хотя пользователь хочет найти по фразе из 10 символов (делая 1 запрос).
Такое поведение не нужно, т.к. если много пользователей будут быстро вводить символы, можно положить сервер.
Для этого создали хук useDebounce.
Если throttle позволял выполнять одно событие раз в какое-то время, то debounce (инструмент похож), но
он позволяет отменять предыдущее событие в течение какого-то времени.
Т.е. до тех пор, пока мы что-то вводим в инпут, колбек вызываться не будет.
Как только пройдёт время (delay), тогда будет вызван колбек, а все предыдущие вызовы отменены.
если в ref timer есть какой-то таймаут, то в начале он очищается.
В таймауте будет вызываться колбек с переданной задержкой.
Т.е. каждый раз при вызове функции таймер очищается и создается новый таймер.
До тех пор, пока таймер очищается, функция вызвана не будет.
Т.е. если пользователь вводит что-то и разница по времени между нажатиями на клавиши входит в диапазон таймера,
то таймер будет очищаться и запрос не будет отправляться.
Для использования передаем в хук колбек с запросом и задержкой const debouncedFetchData = useDebounce(fetchData, 1000);
И в хендлере для onChangeSearch вместо fetchData вызываем debouncedFetchData.
Так же есть еще ньюанс, что когда фильтры переключаются их состояние нигде не сохраняется и при перезагрузке страницы они сбрасываются на дефолтные.
Реализовали подставление состояния выбранных фильтров в строку роута.
Мы сможем так же ссылку передавать с фильтрами или сохранять.
Воспользовались стандартным api браузера window.history.pushState.
Чтобы удобно работать с этими параметрами можно использовать готовое решение из react-router-dom или другое готовое решение, но мы сделали своё.
Добавили shared/lib/url/addQueryParams. В папке url все хелперы для работы со строкой запроса.
По-хорошему функции в shared слое надо документировать, т.к. этот слой используют все и везде.
Использовали useSearchParams из реакт роутера для отображения параметров из урл при инициализации компонента (в initArticlesPage).
Судя по документации json server можно отправлять фильтры по вложенных полям типа ?author.name=aleksei
Можно сделать фильтрацию по типу статьи.
Создали shared/ui/Tabs (для переключения карточек и выбора статьи).
TODO - написать линтер для проверки корректности пути скоупа компонентов для сторибука

60. Список рекомендаций. Группировка редюсеров. Скроллбар.
Создали articleDetailsPageRecommendationsSlice.
Каждая страница по-хорошему не должна иметь совственной логики.
Мы открываем страницу и там должен быть набор фичей, подкомпонентов, виджетов, ентитов...
Пока что все идет без группировок (articleDetails, articleRecommendations и т.д.).
И если страница большая, там может быть 5-6 редьюсеров, которые декомпозируют логику. Хотя она должна декомпозироваться в фичах и виджетах.
Заинжектили этот новый редьюсер в ArticleDetailsPage (для DynamicModuleLoader).
Тут будет наглядный пример как компонент страницы превращается в бардак, т.к. находится логика на уровне page.
И для чего нужна декомпозиция.
Добавили стилизацию скролбара. Скопипастили стили для хрома, фаерфокса в глобальный index.scss
Потом вернулись к группировке редьюсеров.
По хорошему каждый изолированный редьюсер нужно выносить в фичу, виджет...
Создали обобщающий файл с типами src/pages/ArticleDetailsPage/model/types/index.ts.
Там обьединяющий схемы интерфейс ArticleDetailsPageSchema, который вместо тех добавлен в общую схему.
Так же сделали редьюсер, который эти 2 редьюсера вложенных в себе объединит (через combineReducers).
в src/pages/ArticleDetailsPage/model/slices/index.ts
Чтобы отливливать ошибки присвоения редьюсеров по названию (например в StoreDecorator в defaultAsyncReducers), обновили тип более строго
export type ReducersList = {
    [name in StateSchemaKey]?: Reducer<NonNullable<StateSchema[name]>>;
}
В ArticleListItem при клике на статью изменили открытие роута через navigate на Link с новой вкладкой (так можно открывать на колесико).
Так и с точки зрения семантики правильно.
В reset.scss добавили отмену дефолтных стилей для ссылок.

61. Создание и редактирование статей. Pages.
Создали src/pages/ArticleDetailsPage/ui/ArticleDetailsPageHeader (на уровне page, т.к. он будет специфичен именно для этой page).
Создали селектор getCanEditArticle и вынесли туда бизнес логику проверки возможности редактирования статьи (чтобы не захламлять компонент).
Создали роуты editPage и createPage. Можно было создать 2 разных страницы page, если они сильно отличаются.
Но как правило редактирование от создания мало чем отличается и делается в одном компоненте.
Создание ссылка в навбаре, на редактирование кнопка на странице статьи.
TODO - создать самому функцинал создания / редактирования статьи.
Предполагается что это будет фича или виджет, в зависимости от того, на сколько сложным это будет (в моем понимании).
features/articleEditForm (в фичах разные блоки создания текста, изображения, кода. а в виджетах их объединение либо на самой странице).

62. CopyPlugin. Подготовка к продакшену. Публикация на Netlify.
В первую очередь необходимо разобраться с переводами.
Если сделать yarn build:prod, потом открыть файл со сборкой (build), то там есть js, html, css файлы, но нет json с переводами.
Файлы хранятся в public и нужно что-то сделать чтобы в билде они оказались.
Для этого возпользовались плагином CopyWebpackPlugin (установили copy-webpack-plugin в dev-deps).
В файле config/build/types/config.ts в интерфейс BuildPaths добавили поле locales (путь до файлов с переводами).
И также buildLocales (путь куда переводы необходимо перемещать).
В webpack.config.ts указываем в paths оба поля.
Мы этот путь указывали в src/shared/config/i18n/i18n.ts в поле loadPath.
В config/build/buildPlugins.ts добавляем new CopyPlugin.
После этого, если сделать снова сборку прод, то в build появятся папки с json файлами переводов.
Далее настроили асинхронные файлы (lazy components).
Убрали костыль обертку с таймаутом, чтоб отображались лоадеры с имитацией задержки подгрузки чанков.
Т.е. только такой вариант lazy(() => import('./ComponentPage'));
Сборка долгая (ts loader, babel loader), из-за этого долгая, потом уменьшим в 2 раза.
Т.к. фронт завязан на фейковый бэк, то этот бэк нужно тоже задеплоить куда-то.
Создали отдельно для него новую папку production-project-server.
Проинициализировали его yarn init -y чтоб появился package.json.
Скопировали оба файла из директории json-server в новый проект.
Установили туда необходимые для скрипта пакеты (json-server).
Так же мидлвар cors для обработки запросов из различных источников чтоб браузер не ругался.
Кастомный мидлвар с таймаутом для имитации задержки убрали.
Задеплоим на vercel (nodejs приложение).
https://medium.com/@md.alishanali/how-to-deploy-your-node-js-backend-project-to-vercel-a-step-by-step-guide-f92133c3b5e2

Потом запустим vercel --prod (должен быть глобально установлен).
Возможно нужно будет залогиниться. Прикреплять к текущим проектам не надо, все остальное принимаем на enter.
В конце после деплоя вернется в терминале 2 ссылки
1 ссылка это типа личного кабинета, настройки проекта (https://vercel.com/alexey4717s-projects/production-project-server/hk2pnRvC8d4yfcN4tivYjt883fwd).
2 ссылка на задеплоенное приложение (https://production-project-server-oqn2xb2nf-alexey4717s-projects.vercel.app/).
Если добавить в адрес /articles, то получим 401 error, так можно понять что сервер работает.
Эту ссылку на сервер копируем.
apiUrl мы прокидывали в переменные окружения в конфиге.
Добавили в script build:prod в package.json apiUrl=https://production-project-server-cp4j20w77-alexey4717s-projects.vercel.app
Эти переменные можно как угодно задавать. Через хостинг, в котором делаем деплой, через докер, через файл .env, или прям в скрипте как сделали мы.

Далее деплоили нас react проект (загуглили netlify deploy react).
Это бесплатный и очень простой инструмент, где за несколько минут можно развернуть приложение.
Вот документация:
https://www.netlify.com/blog/2016/07/22/deploy-react-apps-in-less-than-30-seconds/
Вначале зарегистрироваться или авторизоваться.

Потом запушить все изменения для подготовки к продакшену в репозиторий.
В настройках конфигурации на netlify нужно указать 
Build command: yarn build:prod,
Publish directory: build,
Можно было там же прокинуть переменные окружения, но мы указали их в скрипте в package.json.
После успешного деплоя вернется ссылка на развернутое приложение https://stately-raindrop-4d6059.netlify.app/
Так же я добавил в сервере разрешения cors. Передеплоил сервер и клиент.

Создали конфиг файл .toml

Были баги с загрузкой списка. По-умолчанию браузер отправляет запрос на получение html страницы или какого-то контента.
Но поскольку у нас SPA и только один html файл, нам необходимо указать редиректы, чтобы грубо говоря с любого маршрута были проксирования на index.html
На каждый коммит в master ветку netlify перезапускает сборку.

Добавили в api.ts $api.interceptors с присвоением headers.Authorization из локал стораджа, т.к. 1 запрос на netlify был с пустым заголовком и 401 ошибкой.
Так же мутирующие запросы с 500 ошибкой, т.к. версел запрещает вносить записи в исходники (js файл).

63. Оптимизация больших списков. Виртуализация.
Если бесконечно скролить списки и подгружать порции данных с формированием нод в DOM-дереве, но будет постоянно увеличиваться нагрузка на память.
А ноды хранят в себе кучу информации, происходит перегрузка, всё начинает лагать.
Помочь с этим могут виртуальные списки. Загуглили react virtualized.
С виртуальными списками можно иметь оч большие списки.
В момент скрола в DOM-дереве будут находиться только видимые элементы. Количество нод не меняется, меняется их содержимое.
Под капотом у элементов изменяется позиция (top) в стилях (абсолютное позиционирование)
react virtualized уже deprecated, рекомендуется использовать react window. Так же есть react virtuoso (более современное решение).
Мы использовали react virtualized для ознакомления.
Пришлось в packages.json добавить peerDependencies для совместимости версий.
Сделали виртуальным ArticleList.tsx.
Использовали компоненты Autosizer и List из библиотеки.
Он использует свой скролл в отдельном контейнере, а у нас уже был и использовался скролл на всей странице.
Использовали WindowsScroller вместо Autosizer для кастомизации скрола. У него есть пропс onScroll.
Можно компонент перенести в Page.
Сделали вместо renderArticle rowRender. Там передать из аргуместа article не получилось, сделали передачу по индексу как articles[i].
Так же если в WindowsScroller лишняя обёртка, то есть пропс registerChild

В виртуальном списке есть сложность с тем, что нужно прокидывать размеры элементов списка.
Т.е. они не принимают вид под фактический размер элемента, вероятно это из-за абсолютного позиционирования.
Поэтому с плиткой из маленьких элементов нужно подбирать размеры.
Для динамических плиток (small элементов списка у нас) используется Masonry.
Но у нас плитка одинаковых размеров, мы просто добавили условия (itemsPerRow, rowCount) (без реализации 2 разных rowRender).
В rowRender указали fromIndex и toIndex, т.е. с какого до какого индекса будет рендер элементов.
Далее итерируемся с fromIndex до toIndex, пушим в новый массив элементы и рендерим его.
Добавили на ArticleListItem класс, для адаптации стилей под виртуальный список.
В статье так же есть список рекомендованных статей, для них потом уберем виртуализацию.

64. ESlint. Пишем свой плагин. Анализ AST дерева.
Тут был рефакторинг. Есть проблемы с нарушением архитектуры, правильности импортов (относительности, абсолютности).
Доступности к папкам. Создаём плагин, который будет следить за нарушением архитектуры и импортов.
Создадим как отдельный npm-пакет, опубликуем его и подключим. (пакет назвал eslint-plugin-alexey4717-plugin).
Сейчас добавим 1-е правило (в сумме их будет 3).
Создали новую директорию для проекта. npm init -y.
Плагин обязательно должен называться с eslint-plugin.
Для того чтоб установить плагин, можно руками все установить и добавить (есть описания в документации).
Но уже есть готовые решения, которые позволяют всю необходимую структуру сгенерировать.
Выбрали пакет eslint-generator. Для этого установили глобально npm i -g yo и eslint-generator.
Это пакет для инициализации проектов, для создания опросников (типа добавить ts? добавить react?).
Вероятно он стоит например в CRA или подобных средах, когда разворачиваем приложение.
После установки выполняем команду yo eslint:plugin. Указываем имя, название плагина, описание, содержит eslint правила - да.
Перезапишет package.json. Сгенерируется структура.
В папке lib/index.js скрипт все правила из папки rules импортирует, потом экспортирует.
Для создания правила yo eslint:rule. Т.е. плагин может содержать в себе много правил.
Создали плагин path-checker. Это правило будет проверять правильность указания абсолютных и относительных импортов.
Сначала создадим по-простому только относительные, потом допишем и изменим.
В папке rules сгенерился новый файл (можно поудалять комменты).
Работаем в методе create, выше указаны метаданные.
Так же сгенерился одноименный файл с тестами в соответствующей папке.
Там можно описывать как валидные, так и невалидные сценарии.
Т.е. указывается код, запускаются тесты (уже есть скрипт в package.json) линтер этот код через правила пропускает (легко дебажить).

Что такое абстрактное синтаксическое дерево (AST) и как компилируется и преобразовывается код.
Пример в astexplorer.net. Можно посмотреть видео на канале (создание своего ЯП)
Если выделять куски кода слева, то справа будет появляться информация о парсинге (ноды).
Например можно слева добавить импорт и справа посмотреть формирование нод.

Пример создания плагина https://eslint.org/docs/latest/extend/custom-rules
Мы будем работать с getFileName, чтоб понимать где мы находимся и правильно отсканировать пути.
В path-checker.js написали код в методе create.
Сделали проверку на наличие абсолюбных импортов (после автоподставления импорта от вебшторма, там генерились относительные).
Такие места линтер будет подсвечивать.
Указали context.report(node, 'ЛИНТЕР РУГАЕТСЯ'), для проверки выбрасывания ошибки.
Нужно сделать publish в npm.
Во-первых нужно залогиниться, создать аккаунт на сайте npm.
Потом в терминале npm login.
Потом npm publish.
После чего на сайте npm в packages появится опубликованный пакет.
Установим его на проекте как дев замисимость.
В файле .eslintrc.js указываем его в plugins, потом в rules 'alexey4717-plugin/path-checker': 'error'
Для проверки можно открыть любой файл, на ноды с импортами будет ругаться линтер с указанным текстом 'ЛИНТЕР РУГАЕТСЯ'.
После внесения правок в плагин, нужно увеличить версию 0.0.1 и снова npm publish.
Потом на основном проекте обновить версию, заругается линтер. Проверили линтером на всем проекте yarn lint:ts, поправили импорты.
Для shared слоя по-хорошему сделать отдельную проверку, но пока оставляем как есть. (Можно и относительные использовать)

65. Позиционирование элементов. Отступы по дизайн системе.
Мы пишем оя много CSS (Отступы, пэддингиб display flex и т.п.).
В идеале создать UI библиотеку, чтобы охватывались все кейсы, описанные дизайнером в соответствии с дизайн-системой на проекте.
В том числе позиционирование, фиксированные отступы. В идеале стремиться к тому, чтобы CSS не писать для какого-то бизнес кода вообще.
Всё должно собираться из кирпичиков в нашей ui библиотеке.
При этом дизайнер в своих макетах должен точно такие же компоненты, из которых он этот дизайн верстает.
А разработчик это всё переносит уже в код в соответствии с библиотекой.

Создали shared/ui/Stack
Там внутри Flex - будет регулировать расположение элементов, отступы между ними, направление (вертиклаьное или горизонтальное).
Это компонент общего характера. Так же будет 2 имплементации этого компонента, это вертикальный Stack и горизонтальный.
Потом переосмыслили. Создавать union типы гораздо удобнее чем перечисления (enum).
Потому что перечисления приходится импортировать везде, тащить за собой.
А так мы можем описать обычную строку и нам не приходится добавлять лишние импорты и везде таскать за собой перечисления.
Тем более enum которые мы используем после преобразования ts потом преобразовываются в реальный js код, а с типами такого нет.
Удобнее было бы описывать такие стили в css-in-js (прям в пропсах). Но такие библиотеки имеют нулевую ценность в рантайме.
Они более медленные чем классический css, поэтому используем такой подход.
FlexGap определяет дизайнер.
Не используем инлайн стили, т.к. у них высокая специфичность и переопределить из извне будет сложно (с классами такой проблемы не возникнет).
Для убирания подсветки отсутствия перевода строк (например пепедачи атрибутов align), указывает эти строки в eslint.rc\i18next/no-literal-string\ignoreAttribute.
Внедрили VStack и HStack (та самая имплементация с разными directions).
Использовали их в разных компонентах на проекте. При этом удалилось много дублируемых строк стилей (маргины, display: flex...).
Для Flex добавили в пропс булево поле max, в соответствии с которым будет содержимое растягиваться на всю ширину (т.к. флекс по-умолчанию задаёт ширину по содержимому).

66. Семантика.
Для компонента Text сделали тэги группы h, в зависимости от переданного size.
В Sidebar.tsx убрали тэг menu, т.к. он deprecated. Вместо него использовали aside.
В Page.tsx вместо section заменили main.
Для Flex расширили пропсы от пропсов элемента div, для передачи role (смены элемента).
В идеале, особенно если нужна CEO оптимизация, нужно на проекте указывать правильное, с точки зрения семантики тэги.

67. Headless UI. React aria. Listbox.
Продолжили улучшать UI библиотеку. На-пример ресурс headlessui.com (будем использовать её).
Headless библиотеки добавляют нужное поведение на компоненты, accessibility, доступность.
При этом они без вёрстки, супер лёгкие, их можно кастомизировать под себя.
С нуля компоненты без стилей, только с логикой (реакция на нажатия клавиши и т.п.).
Так же есть более мощная библиотека react-aria.
Она предоставляет набор хуков, там можно использовать нативные тэги, на которые можно навешивать функционал.

Модалку делать не будем (уже у нас работает норм).
Можно использовать то, что руками сделать сложно (например слайдеры с поддержкой мобильной версии на touch), чтоб не писать самому.
Особенно если нужна гибкость и кастомизация, можно использовать headlessUI библиотеку.

Добавили пакет @headlessui/react.
В shared слое создали новый компонент ListBox. При нажатии на клавиатуре Enter можно взаимодействовать.
ReactNode - это еще и строка или число.
Использовали ListBox на странице профиля вместо селекторов.
Есть библиотека floating-ui для решения базовых задач с popup. Очень легковесная.
С позиционированием элементов, при скролах, тултипов, высчитывание позиций стрелки, двигание элементов мышью.

68. Dropdown. User avatar.
Вместо кнопки выйти хочется сделать аватарку пользователя и чтобы при нажатии на иконку выпадало меню.
ListBox предназначен для выбора пункта, но не для действий. Т.е. это больший контрол для форм.
Нам нужно меню, в котором можно совершать какие-то действия.
Например, перейти на другую страницу, отредактировать сущность.
В headlessUI это компонент Menu. Мы создали в shared Dropdown.
Использовали его в Navbar.

69. Генератор фичей сущностей страниц на node js.
Мы часто создаем слои Entity, Feature и у них часто похожа структура.
Современные среды разработки позвонляют использовать templates, snippets.
Но некоторые используют VIM или любую другую среду, в которой нет системы создания какой-то сложной структуры папок.
Создадим такой скрипт.

Пример команды, генерирующей слой:
node .\scripts\createSlice\index.js features featureName

Краткое описание скрипта:

resolveRoot.js - выход на уровень корневой директории.

firstCharUpperCase.js - хелпер, который делает 1 букву строки заглавной

index.js - из аргументов достаётся названия слоя и слайса.
process.argv - массив переданных аргументов текущего скрипта (в котором эта команда написана, т.е. index.js и запущен этот скрипт в ноде).
т.е. тут node .\scripts\createSlice\index.js features featureName 
1 арг это абсолютный путь в ОС до файла node.exe
2 арг это абсолютный путь в ОС до файла скрипта
3 арг это тип слоя (features)
4 арг это название слоя (featureName).
Далее делается проверка, что переданы тип и название слоя, что они допустимы.

createTemplate.js - работа со стандартным fs (file system).
mkdir - создаёт папки для слоя и слайса.
В отдельных скриптах создается модель, ui, api.
В которых так же делаются mkdir, fs.writeFile для создания файлов скриптов.
Для создания файлов используется строка в виде кода (шаблонный литерал) с заданной структурой (по аналогии с созданием сниппетов).

Вынесли запуск скрипта в package.json с названием generage:slice

70. RTK query. Начало большого рефакторинга.
Начали с ArticleDetailsPage. Там много лишнего кода.
По-хорошему слой pages должен быть максимально чистым.
Там должно быть перечисление фичей.
Создали фичу articleRecommendationsList.
Папку model удалим, т.к. для получения данных будем использовать rtk-query.

// TODO сделать все как в https://www.youtube.com/watch?v=Od5H_CiU2vM&t=60s для настройки редакса
RTK-Query генерирует хуки для апи (в зависимости от названия эндпоинта),
которые запускаются в теле функционального компонента (похож на хуки graphql).
В них содержится генерируемая логика, типа индикация загрузки, error при запросе, refetch и т.п.
Если запускать хук с одним и тем же запросом в нескольких местах, то запрос технически будет отправляться один,
т.к. данные сохраняются в хранилище. Rtk-query сам кеширует и своевременно обновляет данные.
В хуках так же есть longPulling, чтобы с интервалом отправлять запросы.

Создали инстанс апи для rtk-query (rtkApi.ts).
Нужно как-то асинхронно и лениво инжектить endpoints (с помощью injectEndpoints).
Нужно так же добавить редьюсер, который связан с rtk-query и middleware.
Добавить тип [rtkApi.reducerPath]: ReturnType<typeof rtkApi.reducer>; в StateSchema.

Для проверки, что endpoint подгрузился lazy, сделаем сборку с подключением bundle-analyzer.
В запрос добавим в тело несколько больших строк, чтоб хотябы 2 кб весила и можно было отследить её наличие в бандле.
В bundle-analyzer видно, что main чанк весит столько же. А чанк с подгрузкой endpoint стал весить чуть больше.
Можно сделать вывод, что этот endpoint лениво подгрузился отдельным чанком и в главный не попал.
Поэтому в нужном модуле их можно асинхронно инжектить.

По методологии FSD эти эндпоинты должны располагаться в сегменте api слоя (вместе с определением хука).

TODO AddCommentForm можно было сделать в entity и это была бы переиспользуемая форма.
А потом создали отдельную фичу ArticleComments, используя entity AddCommentForm.
Но т.к. AddCommentForm уже внутри фичи, а фичу в фиче мы использовать не можем, то обыграем это по-другому.
На уровне страницы создали отдельный компонент ArticleDetailsComment.
В ArticlesPage тоже много лишней логики.
Для entity ArticleList по-хорошему, надо было создать отдельную фичу ArticleInfiniteList, чтобы там была вся логика
по подгрузке данных, пагинации.
Но т.к. state находтся на уровне страницы, то прийдётся кардинально рефакторить, переносить стэйт.
Так же создали под папку ArticleInfiniteList.
Так же отрефакторили ProfilePage.
Так ProfileCard (entity), может использоваться как и где угодно. Она зависит от внешних данных и хендлеров.
А сама логика, что отрисовывать, находится на странице профиля.
Для выноса этой логики создали фичу editableProfileCard и отрисовали её в page.
По такому уровню Entity => Feature => Page хорошо будет соблюдена вся композиция

В ProfileCard все принимается извне, но при этом много логики внутри слоя entity.
Перенесли весь этот state на уровень фичи

71. HTML report для тестов.
Для UI тестов уже генерится. Для unit тестов нет (для них и сделали).
При запуске скрипта yarn test:unit не очень удобно просматривать ошибки и понимать что не так с тестами.
Загуглили jest html report. Можно делать свои репорты, но мы подключим готовый.
Подключим jest-html-reporters. После установки пакета, нужно добавить в jest.config reporters.
Изменили publicPath: '<rootDir>/reports/unit' (нужно добавить в git-ignore).
И добавили опцию inlineSource: true, чтоб все генерилось в одном js файле.
Можно туда же сохранять отчет по e2e тестам, локи.

72. Исправляем баг с виртуализацией. Пишем RTL тесты на карточку профиля.
Добавили в ArticleList проп virtualized. Если он true, то рендерим виртуальный лист, иначе просто мапим массив с обычными items.
В ArticleRecommendationsList отключили виртуализацию для списка ArticleList.
Напишем тесты на редактируемую карточку профиля EditableProfileCard с использованием react-testing-library.
Для этого нужно навесить атрибуты data-testid на нужные компоненты.
Предлагается называть такие идентификаторы как <Название компонента>.<Что конкретно тестируем>.
TODO Лучше в ProfileCard повесить id на все инпуты и проверить все кейсы, так же валидацию на все поля сделать.
Так же в компоненте есть DynamicModuleLoader, в который передаются редьюсеры.
Тут компонент протестируется нормально, т.к. редьюсер будет вмонтирован при маунте компонента.
Но в теории может возникнуть такая ситуация, когда мы тестируем вложенный компонент, а state монтируется в родительском компоненте
Тогда нам нужно как мы по аналогии делали в сторибуке добавлять эти редьюсеры асинхронно, на этапе тестирования.
Т.е. в componentRender передавать в StoreProvider asyncReducers
Установили библиотеку @testing-library/user-event
Так же нужно учитывать, что есть useInitialEffect, из-за него фетчинг данных и лоадеры.
Нужно делать его по условию __PROJECT__ !== 'jest' (мы сделали так в useInitialEffect).
Еще лучше вариант замокать запрос и тогда мы бы тестировали реальное поведение компонента
Так же нужно учитывать что экшены userEvent асинхронные, их нужно await-ить.
Можно запускать тэсты с флагом -- --watch, так тесты будут перезапускаться при изменении файла.
Для проверки выполнения успешности запроса в unit тестах, его нужно замокать.
У нас используется инстанс api (от axios). api.put(). Можно использовать jest.spyOn().

73. Роли пользователя. Доступ по ролям. Forbidden page.
TODO нужно будет вынести все z-index в переменные, чтобы разным элементам на странице задать нужные приоритеты.
Кнопка будет иметь z-index пониже, модалка повыше и т.д. (можно посмотреть пример в material-ui, как сделано у них).
Это всё должно лежать в глобальных стилях.

Тут мы занимались ролями пользователя и доступом к контенту по этим ролям (к страницам).
В БД изменили у пользователей role на roles (массив ролей).
Добавили роль MANAGER.

Создадим селектор получения ролей. Потом используя reselect создадим новые селекторы с вычислением булева значения (например isAdmin).
Реселект мемоизирует значения.
Далее создали новую страницу (админ панель), доступ к которой будут иметь только админы.
Добавили роут. В AppRoutesProps добавили roles.
Добавили пункт админка в навбаре. Сделали запрос в AppRouter (чтоб нельзя было вручную в роут перейти через url).
Проверку по ролям можно сделать как в RequireAuth (мы сделали так), так и в отдельном компоненте.

Для пользователя редиректы (при отсутствии права) крайне неочевидны.
Тут по-хорошему надо отрисовывать дополнительный интерфейс, явно писать что пользователю запрещено посещать этот контент.
Для этого создали ForbiddenPage.

74. Исправляем проблемы со STACK.
После использования Stack некоторые элементы ужимаются.
Добавили max им и в некоторых местах использовали VStack.

75. Миграция на 18 реакт. Рефакторинг. Storybook mock addon.
Обновили пакеты react и react-dom до 18.2.0 (они обычно выпускают одинаковые версии). И типы для них
По большей части добавляется явно типизация для children в пропсах компонентов.
Так же были проблемы с совместимостью i18next (обновили пакеты), с react-virtualized тоже (не выходят долго обновления, хотя на момент обучения обновления все таки были).
TODO Предлагается переехать на react-window или react-virtuoso в будущем. 
Пока что закомментили ошибки (я обновил версию пакета).

Так же нужно проверить что работает сторибук. В целом проблем не было.
Но например сторис ArticleRecommendationsList с ошибкой, т.к. не обернуто в провайдер.
Везде где нет добавил Normal.decorators = [StoreDecorator({})];
AddCommentForm это лэйзи компонент, поэтому его обернули в Suspense, т.к. в сторибуке при первой загрузки (инициализации) может упасть ошибка, если сторис уже открыт.
Зачастую прийдется тестировать компоненты с lazy подгрузкой. Чтоб это все не выискивать сделали декоратор.
Создали shared/config/storybook/SuspenseDecorator.
Надо добавить его в config/storybook/preview.js

Так же на проекте используется rtk-query, который надо так же адаптировать под storybook.
Есть Addon decorator для сторибука (storybook mock api).
Установили пакет storybook-addon-mock в devDeps (он для 6 версии или выше сторибука).
https://storybook.js.org/addons/storybook-addon-mock
В конфиге сторибука передать api в DefinePlugin.
Пример использования в сторисах ArticleRecommendationsList.stories.tsx.

76. TS isolatedModules. Рефакторинг. Подготовка к миграции на babel loader.
В проекте на элементах есть атрибут data-testid и он нужен только для RTL тестов.
После сборки видно, что в DOM-нодах этот атрибут остаётся.
Причем он есть как в dev, так и в prod бандлах.
Каждый символ весит какое-то количество байт и от этих id бандл немного прибавляет в весе.
Будем писать свой babel плагин, который будет выпиливать эти атрибуты из сборки.
Но перед этим необходимо подготовить проект.

В целом у нас долгая сборка в dev режиме.
Это из-за того, что у нас работает и babel loader, и ts loader и в рантайме в том же процессе проверяются типы.
Это все достаточно ресурсоёмко, поэтому откажемся от ts loader и будем использовать проверку типом в отдельном процессе.
В tsconfig нужно включить опцию isolatedModules.
При его включении будет ошибка на экспортах типов "Re-exporting a type when the --isolatedModules flag is provided requires using export type".
Так же с этой опцией ts следит, чтобы не было пустых ts файлов.
Если в кратце, то ts компилируется в js, и иногда за эту компиляцию отвечают другие инструменты, типа babel.
И они не всегда понимают полную картину типов, кода. И вот эти вот типы (types, interfaces), их иногда, чтобы упростить сборку,
нужно выносить в изолированные модули (это файлы, в которых находятся только интерфейсы и типы).
И когда мы делаем экспорты или импорты, мы явно указываем type.
Например export type { ArticlesPageSchema } from ...
Тем самым создаётся изолированность модуля.
Это с точки зрения кода хорошо, и с точки зрения перформанса тоже (немного ускоряет сборку).

Мы так же подгатавливаемся к переезду на babel-loader (будем отказываться от ts loader).
Если в файде с типами и интерфейсами находится enum, то их нужно переносить в consts (допустимый сегмент в FSD),
чтобы типы были изолированы как модуль. Там будут храниться enums, константы, статичные объекты и массивы и т.п.
Т.е. типы у нас из кода выпиливаются полностью, а enum компилируется в объект (т.е. по сути это константа).

77. CircularDependency. Кольцевые зависимости.
Установим вебпаковский плагин circular-dependency-plugin (с типами).
Есть и другие мощные инструменты, например DependencyCruizer.
Он помимо кольцевых зависимостей так же умеет следить за "мёртвым" кодом и т.п.

Если в кратце кольцевые зависимости, это когда модуль А использует зависимости модуля Б, а модуль Б использует модуль А.
Чтобы это пофиксить, по-хорошему надо создать модуль С, вынести в него то, что используется в 2-х других модулях и переиспользовать.
Нужно от этого избавляться, т.к. сборщик не всегда этот клубок может распутать.
По итогу может стрелять ошибка или утечка памяти.

В buildPlugins заюзали плагин.
У нас модульная структура и piblicApi, поэтому кольцевых зависимостей не обнаружено.
Правда время сборки немного увеличилось, но мы это будем фиксить в будущем.

78. Миграция на babel loader. Выносим проверку типов в отдельный процесс. Пишем свой babel plugin.
До миграции время начальной сборки составило 8700ms (ребилд с изменённым кодом 2000ms).
Почему так происходит.
Помимо ts-loader есть babel-loader, который тоже обрабатывает код, добавляет пресеты, плагины.
Там нужно отказаться от ts-loader в пользу babel-loader.
Если просто закомментировать ts-loader в файле buildLoaders.ts, то проект не запустится.
Нужно настроить babel-loader, чтоб он мог выполнять задачи ts-loader.
В buildBabelLoader передали isTsx, чтобы мы могли отдельно работать с tsx файлами, и отдельно с обычными ts файлами (их обрабатывать прийдется немного по-другому).
Такое условие обработки test: isTsx ? /\.(jsx|tsx)$/ : /\.(js|ts)$/.

Понадобились @babel/plugin-transform-runtime и @babel/plugin-transform-typescript (для правильной работы с typescript).
В файле buildLoader разделили на 2 buildBabelLoader (1 для ts, другой для tsx).
После этого время начальной сборки составило 4700ms (ребилд с изменённым кодом 372ms).
Это произошло из-за того, что мы избавились от одного обработчика файлов (ts-loader).
Babel-loader в рантайме не умеет проверять типы (среда разработки подсказывает об ошибках, но сам сборщик запускает проект без ошибок).

Можно вынести эту проверку в отдельный процесс и этот процесс никак не будет замедлять сборку.
Для этого нужно установить fork-ts-checker-webpack-plugin
Его можно использовать вместе с ts-loader, либо с babel-loader (как у нас).
Примеры реализации: https://github.com/TypeStrong/fork-ts-checker-webpack-plugin/tree/main/examples
Вставили плагин в buildPlugins файл. После этого проект будет собираться,
но отдельным процессом сборщик будет проверять и выбрасывать ошибку типов, если такая имеется.
В процессе (в терминале) будет нотификация type checking in progress...
В итоге, теперь за компиляцию typescript в js отвечает babel-loader, от ts-loader мы отказались, а проверку типов вынесли в отдельный процесс.

Далее нужно реализовать выпиливание атрибута data-testid из prod-сборки, т.к. он нужен только на этапе тестирования (локально или dev).
Создали config/babel/babelRemovePropsConfig.ts (самописный плагин для babel).
Для понимания как они создаются можно загуглить babel plugin development. https://babeljs.io/docs/plugins#plugin-development
Похоже на создание плагина для линтера, так же работа с нодами в AST дереве
Identifier это нода AST дерева.
Полезно пользоваться ast-explorer когда пишем свои линтеры, плагины, при глобальном рефакторинге и внесении изменений.
Можно парсить код в ноды и потом с ними взаимодействовать.
Укажем глобально ноду Program, для того, чтобы мы могли в плагин прокидывать пропсы.
Прокидывать будем атрибуты, которые хотим выпилить из prod-сборки.
JSXIdentifier - нода для поиска JSX узлов,
но можно и просто Identifier если хотим работать просто с js файлами (так пишутся полифилы, для преобразования кода для старых браузеров и babel).
path.traverse - метод для прохода по всем нодам проекта.

После yarn build:prod можно в main бандле по поиску проверить наличие data-testid.
В buildBabelLoader добавили babelRemovePropsPlugin (по условию isTsx, т.к. просто для ts файлов нет смысла проверять, лишний процесс).
После повторной prod сборки будет только 1 атрибут data-testid (что-то внутри реакта).

79. Popover. NotificationList. RTK query. Polling.
Добавили иконку в Navbar возле иконки аватара, при нажатии на которую должен вываливаться попап.
Сделали shared/Popups, обобщили папку, в ней 3 компонента с похожей логикой (Dropdown, ListBox, Popover).
TODO сделать сторис для Popover
Добавили в bd.json поле notifications.
Создали сущность entities/Notification. И отрендерили список в поповере в навбаре.
Уведомления должны обновляться, нужно реализовать long pooling.
Добавили poolingInterval в ручку уведомлений, из rtkApi инстанса, запрос будет ожидать данных и повторно лететь каждые 10 сек.
Это не сильно нагружает сервер (вебсокет например нагружает еще больше, чем отправка http запроса каждые 10 сек, т.к. там открывается постоянное соединение с сервером).
В Navbar напрашивается декомпозиция на фичи, т.к. много компонентов отрисовывается.
Сделали features/notificationButton как обертка надо нотификациями. Можно будет переиспользовать где угодно.
Сделали features/avatarDropdown.
Когда логика и кусок ui концентрируется в отдельном модуле, его проще перенести в другое место, переиспользовать или удалить,
нежели чем она переплетена внутри другого модуля и нужно точечно из него удалять строки кода или импортировать в другие места.

80. Drawer. Overlay. React-device-detect. Мобилки и десктоп.
Для мобилки нужно будет отображать уведомления по-другому, т.к. они не вмещаются.
Создали в shared компоненты Drawer и Overlay.
Overlay - компонент, который отвечает за затемнение за background в модалках и при нажатии на который, происходит закрытие модалки.
Overlay можно переиспользовать вместе с модалкой или drawer, и в любом другом месте где он нужен.

Установили пакет react-device-detect, который распознает устройство пользователя по user-agent.
Есть другие, которые распознают по размеру экрана например
Для просмотра информации о бандлах пакетов (minified) можно использовать сайт https://bundlephobia.com/
Контент декларативно помещается внутрь BrowserView и MobileView, а либа сама определяет что показывать в зависимости от устройства.
Можно даже сделать 2 разных App для BrowserView и MobileView, и переиспользовать компоненты в lazy режиме.
И важно понимать, что когда мы находимся в desktop, то компонент для мобилки не подгрузится (и наоборот).
Поэтому при тестировании нужно обновлять страницу после смены типа девайса.

81. useModal. Рефакторинг Modal и Drawer.
Если для shared/ui компонентов нужна переиспользуемая логика, можно выносить это в shared/lib.
Между модалкой и шторкой drawer много общего.
Вынесли общую логику в shared/lib/useModal.

82. Динамический импорт. Lazy библиотеки. Провайдер. Gesture, React spring.
Хочется чтоб на мобилке пользователь смог свайпнуть пальцем для закрытия drawer.
Воспользуемся библиотекой use-gesture (для всяких drag-and-drop).
И react-spring для анимаций.
Обе библиотеки увеличили бандл на 60 кб (минифицированная prod сборка), это много.

Как только делается импорт данных из внешних библиотек, они подтягиваются в бандл.
Webpack за счет tree-shaking не включает в бандл либы, если импортируемые данные не используются. 
Научимся лениво подгружать библиотеки только там, где они нужны, отдельными чанками, чтобы в main бандл они не попадали.
Логика по ленивой подгрузке будет в AnimationProvider.
Там через динамические импорты import() будут параллельно подгружаться библиотеки в Promise.all и сохраняться в ref.current.
Далее возвращаться из контекста. Для переиспользования нужно будет нужный участок кода оборачивать в провайдер с отображением нотификации загрузки.

83. Алиасы. Ts Morph. Автоматизация рефакторинга.
Поправили z-index в модалке и оверлее.
Сейчас импорты выглядят без алиасов, просто из корня папки ('features/feature').
Можно добавлять алиасы ('@/features/feature'), т.к. иногда возникают кейсы с пересечениями названий (например каких-то библиотек).
В buildResolvers.ts добавить в alias '@': options.paths.src
В tsconfig.json в path сделать ключ "@*".
После попытки запуска приложение будет много ошибок импорта.
Чтобы вручную все не исправлять будем учиться автоматизировать рефакторинг, работая с AST деревом.

Будем использовать библиотеку ts-morph.
Она предназначена для изменения ts-кода.
Создали scripts/updateImports.ts
В нем будет получение файлов (ts, tsx) из src. Определение наличия абсолютных импортов слоёв FSD через importDeclarations. 
И добавление к импортам алиаса. В конце обязательно project.save() чтоб сохранить изменения.
Запустим скрипт ts-node .\scripts\updateImports.ts
Так же linter будет ругаться, что сначала должны идти импорты без алиаса (т.е. из библиотек), что так же хорошо.
yarn lint:ts:fix
В курсе решили выпилить virtualized (т.к. с ним много багов) из ArticleList.
Но на момент обучения там вышли обновления, поэтому я пока не стал выпиливать.
TODO запилить через virtuozo.

84. BrowserList. Размер бандла. Исправляем Drawer animation provider.
Пофиксили Drawer, вынесли туда обёртку AnimationProvider.

Как babel, webpack понимают для каких браузеров компилируется код?
Где нужно добавлять полифилы? Как делать что бы на всех браузерах код работал?
Есть технология BrowserList. Описывается конфиг, в конфиге указываются версии браузера, которые мы хотим поддерживать.
И babel смотрит на этот конфиг и добавляет полифилы, в зависимости от того, насколько старые браузеры нам необходимо поддерживать.

Сделали yarn build:prod (main чанк весит 446кб).
В корне создали файл .browserslistrc
Можно так же указать опции там (not dead, > 2% (процент пользователей, которые используют браузер), конкретные версии).
Обычно собираются метрики, смотрится кто пользователи, на чем сидят. И в зависимости от этого потом заполняется конфиг.
Опция defaults обычно покрывает большинство кейсов.
Поддерживать Internet Explorer смысла нет.
Снова сделаем yarn build:prod (main чанк весит 433кб).
Он стал весить меньше, т.к. babel перестал добавлять лишние полифилы для старых браузеров, кода становится чуть меньше.
Конфиг можно оч гибко настраивать, что можно даже для определённых стран указать определённые версии браузеров.
Например, условно говоря, в Китае пользователи используют один браузер, в России другой, в Америке 3-й и т.п.

85. Настраиваем Vite. Быстрая сборка для dev.
При изменении кода в разметке, время пересборки у меня составляет примерно 250-450ms.
Есть современные решения по типу vite сборщиков, esbuild.
Попробуем внедрить vite под те настройки, которые у нас уже есть в вебпаке. По идее сборка должна ускориться.
Сам vite настраивается оч легко (не так геморно как с вебпаком).
Нас интересует пресет react-typescript.
Установили @vitejs/plugin-react и vite как devDeps.
Добавили vite.config.
У нас есть scss, aliases. Нужно под это все адаптировать.
Обязательное ксловие, чтоб index.html был в корне.
Скопировали его из public в корень.
Нужно только корректно подключить скрипт до корневого файла.
Создали отдельный скрипт start:vite
установили vite-config-plugin для обработки svg vite.
Мне пришлось обновить react-virtualized по latest. Так же в конфиг vite добавил в esbuild target: 'es6'.
С vite гораздо быстрее пересобирается сборка, за милисекунды.
В Vite для продакшн-сборки используется Rollup, а для разработки — esbuild.

Esbuild очень быстрый и идеально подходит для разработки,
так как он выполняет задачи трансформации (например, компиляцию TypeScript, JSX и т.д.)
в реальном времени с минимальной задержкой.

Rollup в свою очередь более гибок в продакшн-сборке и предлагает более глубокую оптимизацию,
такую как улучшенное tree-shaking, более точное разделение кода и лучшие возможности для создания оптимизированных бандлов,
что критично для продакшн-сборки.

86. StarRating. Модульный подход. Оценка статьи и профиля.
Создадим блок для оценки статьи (shared/ui/StartRating).
Создали entites/Rating, это конкретная бизнес сущность, которая несет оценку продукту.
После указания звезды в десктопе открывается модалка с отзывом, в мобилке дровер.
Модалкой пользоваться в мобилке не удобно, лучше дровер

87. Имплементация оценки для статьи. RTK mutations, queries.
Тут делали конкретную имплементацию для оценки статьи на уровне feature.
TODO нужно будет сделать оценку профиля (Так же примерно, как и на странице article-details, как вам этот пользователь?).
В БД сделали хранение оценок. Создали api article-ratings и profile-ratings.
С точки зрения БД это должны быть разные таблицы.
Так же для ArticleRating сделали lazy импорт, т.к. компонент не является важным, он находится внизу страницы.
И такие компоненты желательно подгружать асинхронно.
Т.к. подгружать в main чанк их особо смысла нет, т.к. отрисовываются снизу и их не видно в момент инициализации (возможно пользователь и не будет скролиться).
Suspence оборачивается уже в файле async с lazy компонентом.

88. Алиасы в сторибуке. Приводим сторибук в порядок.
После реализации алиасов для импортов, сломалась сборка сторибука.
Т.к. там свой вебпак конфиг и нужно его донастроить.
В файле config/storybook/webpack.config.ts
Добавили config!.resolve!.alias (развернули старые алиасы которые могли быть в вебпаковском конфиге сторибука и добавили новый).
В целом сторибуку мало уделяли времени и там образовался бардак.
В shared слой затисались всякие entities из-за сниппетов разворачивания.
Сторикейсы нужно привести к какому-то порядку. Чтоб названия слоёв соответствовали источникам.
Добавили в некоторых компонентах обязательные пропсы, StoreDecorator с данными
Для сторисов если есть мок rtk-query запросов обязательно нужно добавлять StoreDecorator, т.к. это апи redux, и withMock декоратор.
TODO - доисправлять сторисы

89. Опции в линтере. Добавляем поддержку алисов в наш eslint плагин.
После добавления алиасов сломался не только сторибук.
В принципе ресолвинг модулей штука достаточно серьёзная и она охватывает не мало моментов и ньюансов.
Недавно мы писали линтер, который проверял использование относительных путей внутри модулей.
После добавления алиасов он сломался.
Т.е. в рамках модуля используется абсолютный импорт зависимостей этого же модуля, но линтер не выдаёт ошибку.
Перешли в наш самописный плагин. И прежде чем его править, покроем его тестами.
Как раз там есть сгенеренная директория tests, в new ReluTester.
В ruleTester.run есть valid и invalid (примеры правильные и те, где должна вылезти ошибка).
В invalid с такими настройками
    filename: "C:\\Users\\Alexey\\Desktop\\project\\src\\entities\\Article",
    code: "import { Article } from 'entities/Article'",
    errors: [{ message: "all paths must be relative inside the same slice", }],
Запускаем скрипт npm run test
Там интерфейс как у jest, должен тест быть пройден.
Если в тестах добавить алиас, то тест не будет пройден. Нужно исправить код для алиасов.
Нужно настроить плагин так, чтобы можно было использовать любые алиасы, и при изменении не приходилось каждый раз менять их в коде плагина.
Чтобы из проекта можно было прокинуть опцию и плагин адаптировался.
В файле скрипта в методе create получаем alias из context
    const alias = context.options[0]?.alias ?? '';
Если alias передан, то делаем реплейс строки импорта importTo с удалением алиаса.
Подняли версию плагина и запушили. В проекте обновили версию пакета плагина в package.json.
В файле eslintrc для этого правила передали опцию, так же как и для других правил.
Иногда в вебшторме линтер тупит и нужно его перезагрузить в settings/languages and framework/code quality/eslint.
Т.е. disabled и снова enabled. Либо перезапустить webstorm.
Проверили проект скриптом yarn lint:ts для выявления ошибок с импортами

90. Ограничиваем доступ к внутренностям модуля. Public api imports.
Если тебе физически явно что-то не запрещают, то ты обязательно это нарушишь.
Разрешается импортировать из внешнего модуля только то, что предоставляет publicApi.
Т.е. так import { Scheme } from '@/entities/Entity'
а не так import { Scheme } from '@/entities/Entity/model/types/entity'
Необходимо выбрасывать ошибку в таком случае для запрета поломки инкапсуляции модулей в проекте.
Должна быть изоляция внутреннего содержимого модуля от внешнего окружения.
Создадим плагин, который будет физически запрещать внутрь модуля залезать.
В папке с плагинами ввели команду yo eslint:rule
Название плагина - public-api-imports.
Проверяем только абсолютные импорты.
Делим путь на сегменты [entities, article, model, types].
Если что-то есть после article, то это уже нарушение модульности.
Проверяем все слои кроме shared и app (entities, features, wigdets, pages).
Так же публикуем новую версию, скачиваем на проект.
Запустили скрипт yarn lint:ts. Пофиксили все импорты не из паблик апи.
Для файлов тестов потом сделаем другие правила, т.к. в них могут экспоритораться редюсеры и т.п.,
Что в нетестовых файлах может нигде не использоваться.
Чуть позже добавим линтер, который будет удалять неиспользуемые импорты.

91. Testing public api. Micromatch. Тесты на eslint плагин.
В файле shared/config/storybook/StoreDecorator есть ошибки из нового плагина, которых быть не должно.
Помимо продакшен кода, который пользователь видит в браузере,
У нас есть вспомогательный код для разработки (тесты, сторисы и т.п.).
Для таких файлов будем создавать отдельный файл с publicApi, который будет называться testing.ts.
Там будет импорт вспомогательного кода, который не нужен в проде (экшены, редьюсеры и т.п.).
И такой код (благодаря линтеру) не получится импортить в продакшен коде из тестового паблик апи.
В таких файлах будет импорт не такой
    import { loginReducer } from '@/features/AuthByUsername/model/slice/loginSlice'
а такой
    import { loginReducer } from '@/features/AuthByUsername/testing'
Подготовили линтер, чтоб на testing api он не ругался.
Но, чтобы мы случайно в наш код не затащили какие-то моки или редьюсер, который там не нужен,
нам необходимо понимать, какие файлы являются тестовыми.
Определять мы это будет не на уровне самого плагина, а через передачу внешних параметров в файле eslintrc.
Передали в плагин testFilesPatterns: ['**/*.test.*', '**/*.story.*', '**/StoreDecorator.tsx'].
Т.е. если захотим поменять расширение файлов на testing например, то просто изменим параметры для передачи в плагин.
Чтобы при этом не пришлось лезть в код плагина и менять это руками там.
В плагине добавили проверку, чтоб не выбрасывать ошибку импорта из index.ts publucApi в тестовых файлах.
И плюс проверку для тестовых файлов, что импорт не из publicApi (testing.ts).
Воспользуемся библиотекой micromatch, для работы с путями, globs.
Globs - паттерны для работы с путями.

92. Рефакторинг конфига роутера.
В shared/config/routeConfig есть определённые нарушения архитектуры.
Во-первых, импортируются pages из вышележащих слоёв в нижележащие.
Во-вторых, не очень удобный синтаксис.
Создали папку с конфигом на уровне роутера в App, т.к. он все равно используется только там.
Перенесли RouteConfig туда. Остались в shared enums, типы и константы для роутера.
В shared/types создали файл с типами.
И в shared/consts/router.ts файл с константами.
для типа используется UserRole из слоя entities, который так же вышележащий.
Пока оставим так, может потом вынесем этот тип в shared.

93. Layer imports. Улучшаем правила арх-ры. Запрещаем импорт из верхних слоев.
Напишем новое правило, которое следит за импортами по слоям layer-imports
чтобы нижележащие не могли использовать импорты из вышележащих.
Там так же учитываются алиасы. Есть объект layers в котором описано, какие слои могут использовать другие слои.
Как исключение, entities могут использовать другие entities.
Т.к. на практике такие пересечения все-таки возникают, сущности могут взаимодействовать и зависеть друг от друга.
Проверка только для абсолютных путей. Отсекаем все другие импорты (библиотеки).
Валидное исключение StateSchema из app слоя (приходится импортить, TODO от себя, можно попробовать объявить в global.d.ts).
Но впринципе так можно добавлять исключения (описано в последнем тест-кейсе, где импорт StateSchema).
Подняли версию плагина и сделали publish. Обновили на проекте. Добавили использование в eslintrc.js.
Добавили ignoreImportPatterns: ['**/StoreProvider'] где StateSchema.
Потом прогнали тесты yarn lint:ts, пофиксили ошибки.
Перенесли в shared/consts/theme.ts. Enum Theme перенесли туда. Константу для localStorage для theme тоже перенесли в константы для локал стор.
Перенесли в shared/lib/hooks/useTheme.
Перенесли ThemeContext в shared/lib/context
В shared слое не критично, если будут абсолютные импорты внутри него между файлами.
ThemeSwitcher и LangSwitcher перенесли в фичи, т.к. они используются в Sidebar.
В некоторых местах могут быть исключения для правила импортов, если это не бизнес код (для тестов или сторисов). TODO возможно добавить в testing.ts publicApi.
После фикса запустили проект для проверки работоспособности.
В итоге разработчики больше не смогут нарушать правила на проекте по импортам и хранениям данных в слоях.
Только путём осознанного комментирования линтера, что можно заметить на код ревью.

94. Shared UI public api. Автоматизация рефакторинга.
С точки зрения архитектуры для shared компонентов publicApi не нужен, т.к. там нет модулей, там 1 компонент и его можно импортировать напрямую.
Но с точки зрения красоты импортов publicApi можно создать (внутри каждой папки компонента).
Создали скрипт (scripts/refactoring/createPublicApiForSharedUi.ts),
с помощью которого автоматизированно поправим импорты shared/ui, создадим там publicApi (index.ts).
Для запуска ts-node ./scripts/refactoring/createPublicApiForSharedUi.ts
Потом yarn lint:ts --fix

95. ESLINT Плагин на неиспользуемые импорты.
Вообще webpack умеет делать tree-shaking кода и избавляться от неиспользуемых импортов в сборке.
Но тем-не-мение такие импорты засоряют код.
Есть плагин для линта eslint-plugin-unused-imports, установили его как devDep.
Добавили в конфиг в массив plugins unused-imports. В rules 'unused-imports/no-unused-imports': 'error'.
Потом yarn lint:ts --fix
Еще есть популярный плагин eslint-plugin-import (TODO скачать потом и настроить под себя).
Можно делать особый порядок (сначала с библиотек, потом с исходников абсолютные и относительные, можно отдельно импорт типов, пробелы между ними).

96. Делаем автофикс для public api линтера.
Нужна автоматизация для исправления импортов из public api.
Т.е. из такого import { Counter } from '@/entities/Counter/ui/Counter' руками приходится делать такой import { Counter } from '@/entities/Counter'.
Немного переделали public-api-imports в директории самописных плагинов.
Добавили fixable: 'code', чтобы автоматически он исправлялся.
На сайде доки по eslint в разделе working-with-rules можно найти пример работы с fixer
Тесты из-за автофикса пока что в плагине не работают, чуть позже исправим. Бампнули версию плагина и сделали publish.
Теперь проверили на некорректном импорте, Alt + Enter -> fix... (или на сохранение если включена галочка) Произошел автофикс.
При желании можно написать линтер с автофиксом относительных путей (для того правила, что уже готово),
но там прийдется с матчингом относительных путей заморочиться

97. Документация проекта.
Обновили readme.md
Удобно когда подробно описана документация, скрипты, объяснения.
Как для разработки, так и для внешнего пользователя, который смотрит проект.
Можно ссылаться на неё для новых разработчиков (как 1 из этапов онбординга, для максимально быстрого погружения в проект).
Из главной readme можно делать ссылки на дополнительные readme, где подробные описания (у нас в папке docs).
Либо ссылаться на какую-то внешнюю конфу, где описания так же более подробные.

Обычно в readme описываются скрипты. Могут быть описания по архитектуре.
По тестам, сторибуку, линтингу (особенно если есть самописные плагины как у нас).
По конфигурации, сборщику, переменным окружения.
Про CI pipeline, commit хуки, какие проверки есть, как они выполняются.
Про работу с данными, с помощью чего с данными взаимодействуем, как отправляем запросы на сервер, как нормализуем данные,
как подгружаем редьюсеры асинхронно.
Можно документировать сущности и фичи и делать ссылки на них, т.к. проект разрастается, сущностей становится много.
Особенно это полезно когда начинают уходить менеджеры, разработчики (кадры меняются) и информация забывается.
Т.е. в каждой entity или feature создаётся файл readme, там продуктовые описания для чего она нужна и ссылка на неё из корневого readme.
Если продукт долгоживущий, можно описывать publicApi (что за редьюсеры, схемы, енамы).
TODO нужно подробно везде все описать в entities, features и пр. (во всех документациях).

Можно документировать технические вещи (shared) но не везде.
Это имеет смысл делать в часто переиспользуемых хуках, хелперах, функциях.
Прям в файлах в комментах, с помощью js или ts-doc.
Когда сам пишешь, может показаться что всё понятно и дока не требуется, но для других разрабов это может быть не так очевидно.
Но опять же, код должен писаться как самодокументируемый, т.е. с понятными неймингами, типизируемый, чтобы в нём было легко разобраться.
Можно так же документировать shared/ui, пропсы

JSDoc - это формализованный стандарт документирования кода.
Он поддерживается редакторами кода (автодополнение, подсказки).
Может использоваться инструментами, такими как typedoc, для генерации документации по скрипту в папку docs.
Для быстрого написания (шаблон) ставится курсор перед функцией, пишется /** и нажимается Enter.
Можно использовать свои сниппеты для шаблонов.

98. Алиасы в jest. Fullscreen mode storybook.
Давно не проверяли юнит-тесты, скопилось 13 ошибок.
В частности ошибки с алиасами, jest не может понять что это, т.к. для него не был обновлён конфиг.
В config/jest/jest.config.ts в опции moduleNameMapper добавили '^@/(.*)$': '<rootDir>/src/$1'
После этого ошибки в юнит тестах исчезли.
В config/storybook/preview.ts добавили layout: 'fullscreen' чтоб не было лишних пэддингов и разницы в цветах темы.
Можно сделать свой декоратор для сторибука, чтоб компоненты не прилеплялись к углу, чтоб были небольшие пэддинги и т.п.
Так же давно не запускали скриншотные тесты.
TODO с ними какие-то проблемы, не запускается сервер в chrome.docker Failed fetching stories because the server is down

99. Storybook addon theme.
По-умолчанию в сторибук зашит аддон, который может переключать цвет заднего фона.
Но так же есть аддон, который позволяет навешивать классы, которые отвечают за темы.
На корень storybook/preview. Называется storybook-addon-themes. Он понадобится чтобы удобно переключать наши темы в свитчере.
Установили аддон на проект. добавили его в config/storybook/main.ts.
В сторибуке будет иконка сверху (похожая на 2 горы), там можно переключать темы (но сначала они не будут работать).
Нужно в config/storybook/preview.ts добавить параметры themes.
Так же для addon-essentials нужно выключить аддон для переключения бэкграунда (расширили конфиг в main).
После этого если перезапустить сторибук, то будут переключаться темы на этой иконке.
Дефолтную тему можно так же при желании поменять.

100. Generic components.
Преобразование типов через as влечет за собой вероятность появления ошибок.
Докрутили передачу дженерика в Select.

101. Однозначное сопоставление типов в ReducersList.
Тут фиксили тип для DynamicModuleLoader, но у меня и так уже было пофикшено.

102. Улучшаем и стандартизируем работу с роутером.
В некоторых местах приходится формировать маршруты примерно так
     ${RoutePaths.article_details}${article.id}/edit
Это не совсем удобно.
Сформировали роуты в виде функций const getRouteProfile = (id: string) => `/profile/${id}`
Чтоб не склеивать строки из разных кусков в разных местах.
Будем вызывать функции, передадим аргумент и будем уверены что сформируется правильный маршрут.
Для константы RoutePaths формироваться будет так getRouteProfile(':id'), а для реальных маршрутов будет передаваться реальный id.
В routeConfig и в компонентах заюзали все эти функции вместо RoutePaths.
При ручной склейке можно лишний слеш добавить или наоборот пропустить и в целом неудобно пользоваться и искать.

103. Рефакторинг entities и features.
Были некоторые ошибки. Например, в сущности статьи находятся переключатели отображения статей, типов, поля и отображения сортировка.
Сделали 3 фичи. ArticleSortSelector, ArticleTypeTabs, ArticleViewSelector. Вынесли это из entities/Article.

104. Улучшаем сборку. Babel loader cache. Postinstall hooks.
Из config/build/loaders/buildBabelLoader.ts выпилили плагин i18next-extract, т.к. не пользовались им (оказался багнутым, либо неправильно настроен).
Плагин babelRemovePropsPlugin испольщовался и в дев и в прод сборках (а нужно только в прод), добавили соответствующее условие.
Так сборка дев будет быстрее, т.к. чем больше плагинов, тем больше нагружается сборщик и медленнее она происходит.
Добавили exclude node_modules в cssLoader (по хорошему их везде надо исключать, чтоб не было случайных обработок такой большой папки).
Так же в cssLoader был MiniCssExtractPlugin, который есть так же и в config/build/buildPlugins.ts (в дев режиме и в прод).
Сделали его пуш только для прод сборки в buildPlugins, т.к. использовать его без лоадера смысла не имеет.
CopyPlugin тоже нужен только для прод сборки, чтоб переместить переводы из папки public в папку build.
Так же можно чучуть ускорить сборку, в файле .browserslistrc для прод все браузеры, а для дев только 2 последних версии определенных браузеров.
Тем самым babel прийдется меньше работать, т.к. под старые браузеры код оптимизировать не надо.

Так же сборку сильно нагружают карты исходного кода (source-map).
В файле config/build/buildWebpackConfig.ts для devtool указали eval-cheap-module-source-map как это рекомендуется в доке (быстрее ребилд, для дев режима, для прода медленно).
У лоадеров (у нас babel-loader, основной инструмент сборки, на который идет нагрузка) обычно есть кэши.
Там сохраняются какие-то куски кода, которые редко меняются. При ребилде лоудеру не нужно заного их билдить, он берет из файлов кэша.
В buildBabelLoader добавили cacheDirectory: true.
Например, в директории node_modules тоже есть папка .cache, при запуске сервера там появится папка babel-loader.
Особенно заметен прирост если большая кодовая база (будет формироваться много кэша). На маленьком проекте разница будет не ощутима.

Post-install хуки. Кэши периодически нужно очищать, особенно когда устанавливаем новые библиотеки.
Добавили скрипт postinstall, который будет выполняться после любой установки зависимостей.
Мы указали там удаление директории .cache в node_modules.
Для линукса или мака можно написать rm -rf для рекурсивного удаления, на винде скорее всего не отработает.
Скрипты должны быть универсальны ибо это антипаттерн (т.к. разрабы работают на разных устройствах).
Создали scripts/clear-cache.js. Там с помощью стандартных средств nodejs (path, filesystem) удалили эту папку на postinstall.

105. BuildSlice. BuildSelector. Улучшаем работу со state. useActions.
Основная работа со стейтом происходит через диспатчи и селекторы.
И не очень удобно постоянно диспатчить экшены, получать данные через селекторы.
Нужен механизм, с помощью которого можно будет напрямую получать данные без useSelector и напрямую диспатчить экшены без dispatch.
Будем напрямую биндить диспатч и селектор к данным.
Создали src/shared/lib/store/buildSlice.ts и buildSelector.ts
На примере Counter использовали.
     const [useCounterValue, getCounterValue] = buildSelector((state) => state.counter.value)
Сам селектор (getCounterValue) можно использовать например в asyncThunk, а useCounterValue уже напрямую в компонентах (вместо useSelector(getCounterValue)).
Т.е. с помощью хука buildSelector биндится селектор и мы избавляемся от нужны постоянно использовать useSelector с компонентом (меньше кода).
В buildSlice обертка (вместо createSlice), которая внутри себя будет добавлять нужный нам функционал.
Джинерик взяли из createSlice (можно провалиться в либу).
@reduxjs/toolkit/dist - папка куда билдится редакс, можно оттуда брать типы
Из buildSlice вернется хук useActions, внутри которого все экшены будут сразу оборачиваться в dispatch и их можно было переиспользовать без диспатча.
Action-creators биндятся через bindActionCreators к диспатчу (мемоизируются, чтоб ссылки не менялись).
Добавили @ts-ignore, т.к. возвращаемый результат не соотносится с typeof slice.actions.
В counterSlice.ts сбилдили своим хуком слайс, извлекли из него useCounterActions
Использовали так: const { increment, decrement } = useCounterActions(). Не нужно использовать диспатч, это удобно, меньше бойлерплейт-кода.

106. Работа с изображенями. AppImage, Preload, lazy.
У нас есть кейсы, когда изображение в db не подгружается, т.к. ссылка становится недействительной.
Так же изображения могут долго подгружаться, особенно на телефоне со слабым интернетом.
Научимся lazy загружать изображения и отображать fallback со скелетоном.
Создали src/shared/ui/AppImage для этого.
Внутри использовали не useEffect, а useLayoutEffect, т.к. он вызывается до того, как компонент вмонтируется (даст буст в производительности).
У img есть боработчики событий onload и onerror.
Начнется фоновая подгрузка изображения, после создания Image и присваивания ему src.
Т.е. useEffect запускается асинхронно после монтирования компонента, а useLayoutEffect синхронно перед монтированием.
Использовали вместо элемента "img" компонент "AppImage" в статьях и аватаре.

107. Тесты на роутер. Обновляем RTL.
Нужно тестировать роуты авторизованного пользователя, по ролям, 404 страница, forbidden page, открытие страницы.
Написали рядом файл src/app/providers/router/ui/AppRouter.test.tsx
Повесили на Page атрибуты data-testid для их поиска при тестировании.
Создали отдельный интерфейс TestProps, чтоб расширять нужные элементы без необходимости явного указания в каждом компоненте.
Если нужно будет, можно расширить этот интерфейс.
В тесах используем не getByTestId, а findByTestId, т.к. компоненты загружаются асинхронно.
Но это изначально не помогло, т.к. нужно было обновить RTL пакет (после обновления версии реакта это необходимо было сделать).
Если хочется запускать тесты прям из вебшторма, то нужно указать в настройках плагина путь до конфига jest, т.к. webstorm автоматически найти его не может.

108. Lint staged и pre commit хуки.
Привели pre-commit хуки к виду, похожему на вид для реальной бизнес-разработки.
В файле .husky/pre-commit lint:ts прогоняет все файлы проекта.
Представим ситуацию, что мы изменили 3 файла, делаем коммит, а линтер прогоняет абсолютно все файлы (даже не изменённые вами).
Это может занимать 5-10 минут.
Есть специальная библиотека lint staged. Она позволяет прогонять линтером только те файлы, которые были изменены.
Такой функционал можно написать и самому, можно смотреть на dif гита или кеши (и достать оттуда только те файлы которые менялись), но мы будем использовать "lint-staged".
Чтоб его использовать с husky нужно в package.json добавить объект для поля "lint-staged".
Либо создать отдельный файл lintstaged.rc
Регуляркой укажем, что проверять только ts и tsx файлы.
Чуть позже можно будет добавить к "lint-staged" еще и prettier и stylelint.
В файле .husky/pre-commit вместо lint:ts оставили только npx lint-staged. В итоге прекоммит хуки будут выполняться быстрее и не будут раздражать разрабов или тормозить процесс разработки.

109. Генерация отчета для скриншотных тестов в CI. Github pages and jobs.
От локального запуска скриншотных тестов особого смысла нет, потому что в какой-то момент они начнут запускаться и прогоняться слишком долго.
Т.к. компонентов становится много, стори-кейсов много, ссответственно и скриншотов много. И на их проверки нужно время.
Поэтому эти тесты лучше прогонять в CI pipeline перед тем как мёрджить код в ветку (main/master).
В файле .github/workflows/main.yml лучше изменить run: yarn install на npm install ci (для yarn install --frozen-lockfile).
Это специальная команда, которая предназначена для более быстрой установки зависимостей именно в CI.
Там не создаётся новый package.lock файл и используется уже существующий.
Если посмотреть в CI pipelines в job`e со скриншотными тестами, можно увидеть ошибки скринов, но не понятно из-за чего они.
Хотелось бы чтобы прям в CI можно было посмотреть отчёт.
В amin.yml закомментили старый функционал и добавили новый.
Там есть доступ с пермишенами. Теперь 2 jobs, она для проверок, которая не требует сборки (линтинг, unit тестирование).
А другая для тех проверок, которые требуют сборки (скриншотное тестирование, генерация html репорта...).
Т.е. эти 2 jobs будут запускаться параллельно и не будут влиять друг на друга.
Там указываем что папка .loki она будет со статикой, которую необходимо раздать (report). Чуть позже будем раздавать репорт для unit тестов.
Для того чтобы github pages работали, нужно в настройках проекта (settings/pages) их включить.
Github pages работают либо только для платных (коммерческих) проектов, либо для публичных проектов (мы выбрали публичный).
Source выберем как github-actions.
В yml файле в jobs можно указывать зависимость одной джобы от другой (указав needs поле и передав массив названий job от которых она зависит).
Если провалиться в ошибки в CI по скриншотам, то там будет ссылка на пейджу на статический репорт файл (обычно поиск по index.html, но у нас report.html).
TODO В сторке сторибука нужно будет поправить настройку для FileLoader и сделать её одинаковой
UPD: мне также пришлось в файле main.yml подымать версии некоторых artifact до 3 или 4 (т.к. старые 1-2 были deprecated).
TODO нужно будет попробовать перейти на 22 Node в CI (т.к. сейчас используется 18) и обновить использование artifact и пр до latest.

110. Отчет для юнит тестов в CI.
Перенесли процесс unit testing в джобу build-and-ui-testing перед генерация html репортов
Поменяли path на reports, но отчеты из папки .loki нужно переместить в папку reports (отдельный процесс move loki).
Т.е. на уровне CI будет переноситься директория loki в reports и потом читаться отчёты оттуда.
Потом необходимо сделать index.html файл и положить его в корень reports (как связующее звено) со ссылками на репорты скриншотных и юнит тестов.
Можно её приукрасить и сделать поприятнее при необходимости.
Можно по каждому коммиту при генерации отчета генерить хэш в урле, чтоб был униклаьный путь до html отчета.

111. Автофикс для ESLINT правила на относительные пути.
Обновили самописный плагин, чтоб path-checker автоматически исправлял абсолютные пути на относительные, в пределах модуля.

112. Исправляем проблемы с зависимостями. Обновляем сторибук.
При установке пакетов появлялись проблемы с зависимостями между их версиями (у меня такого не было с yarn).
У них при установке пакетов появлялись errors в терминале, ошибки были с редаксом, сторибуком, react-virtualized.
Они удалили react-virtualized, а не стал (ибо вышла новая версия, обновился).
Обновили react-redux и redux-toolkit, сторибук (через npx storybook upgrade).
После этого у них остались только ворнинги, которые по-зорошему тоже надо фиксить.
У них были ошибки запуска сторибука (у меня нет), вынесли webpack.config в main.ts в поле webpackFinal.

113. Введение в е2е тестирование с Cypress. Тесты на роутер.
На данный момент у нас есть тесты с jest, loki и react-testing-library.
Все их можно назвать unit тестами, они проверяют отдельно взятые компоненты, функции, вёрстку.
Настал момент написать e2e тесты, которые будут проверять работоспособность приложения целиком в браузере на реальных данных.
Это одни из самых важных тестов. Они отлавливают высокоуровневые ошибки, которые не способны отловить некоторые unit тесты.
Для их реализации будет использовать одно из самых популярных решений - Cypress (полноценный фреймворк для написания тестов).
Есть также web driver (более низкоуровневое решение).
После установки cypress сделали скрипт в package.json test:e2e.
При запуске скрипта откроется десктопное приложение. Выбираем e2e тесты.
В корне проекта появится папка cypress.
В ней есть конфигурация для e2e тестов.
Так же есть команды - набор функционала который мы можем зашить внутрь cypress.
Например, функционал логина, драг-энд-дропа и т.д. Можно создавать в любом количестве.
ts ругался на cypress. Создали для него отдельный конфиг cypress/tsconfig.json, добавили там расширение нашего дефолтного конфига.
Чтоб настройки для cypress были примерно одинаковыми с нашим проектом.
Главное в конфиге это поле types, благодаря нему будет работа с типами и они будут подсказываться.
Так же рекомендуется поставить плагин cypress support.
В запущенном процессе прям из ui в браузере можно развернуть тесты или посмотреть примеры реализации и его возможности.
Файлы с расширением .cy.js, в них тесты пишутся с похожей структурой как в jest
В браузере в cypress приложении нажимаем create new spec.
Нужно запустить приложение, чтоб через cypress его прогонять.
Так же в корне приложения создался конфиг cypress.config.ts, в котором можно задавать определённые настройки.
Добавили baseUrl - основной адрес сайта. Так же можно передавать ссылки на стен окружение, тестовые среды, стенды в рамках поднятия CI-CD.
Pre-prod стенды, которые гоняются на каких то данных приближенных на проде (или копия данных с прода).
После этого не нужен в тест кейсах в cy.visit указывать полный адрес, достаточно вложенный типа /.
При описании тестов на логин, не нужно логиниться через нажатие на логин и ввод данных в форму.
Это антипаттерн. Правильным подходом будет написать запрос на сервер, который вернет необходимые авторизационные данные.
Потому что авторизация нужна будет в 90% кейсах, которые хочется протестировать. И делать это через интерфейс долго и не безопасно.
Т.к. команд будет много, лучше это декомпозировать в отдельные файлы в commands.
Пользовательские данные (login, password) для тест кейса лучше хранить секьюрно, в секретнице, в переменных окружения, так чтобы в коде просто не лежали.
e2e тесты в 1 очередь должны проверять глобальную работоспособность приложения в связке с бэкендом (полная интеграция).
Всё что можно протестировать в изоляции на фронте, должно тестироваться с помощью jest, RTL или скриншотов.
Потому что e2e тесты дорогие, они гоняются в реальном браузере, занимают много времени.
Т.е. нужно отправлять запрос на авторизацию, каких-то других данных, их сохранение. Это может работать нестабильно и поддерживть такие тесты сложнее.
Т.е. unit тестов должно быть много, а e2e должны писаться только на интеграцию с бэкендом, только на критический функционал.
Например сохранение профиля, авторизация, удаление/создание каких-то данных. Не проверяется отдельная работа кнопок, модалок и т.п.
Проверяется конкретная интеграция с бэкендом.

114. e2e тесты. Запросы, авторизация. тесты на профиль, статью, комменты, оценку.
Тут писали е2е тесты на профиль и article list.
beforeEach отрабатывает перед каждым тест кейсом. afterEach - после каждого тест кейса.
Например, у нас в beforeEach происходит авторизация (чтоб для каждого тейст кейса её не делать).
А в afterEach сброс данных (в профиле) к дефолтным, т.к. при тестировании они мутируются в БД.
В declare нужно указывать команды, чтоб типизация подхватывалась (например в cy.login()). Вынесли её в commands/common.ts.
Так же добавили метод getByTestId для cy, добавили в глобал типы, так будет проще пользоваться поиском элементов, без большого бойлерплейт кода.
Все, что переиспользуется, выносится в отдельные команды и глобал типы.
Можно добавлять команды как Cypress.Commands.addAll и передавать туда весь модуль (со всеми именованными импортами).
Проверки делать внутри команд не нужно (там исключительно только какие-то действия, нажатие на кнопку, ввод в интуп и т.п.), они делаются внутри тест кейсов.
TODO нужно будет написать тест кейсы на поиск и сортировку статей.
Для тестов статьи вопрос, какую статью тестировать, т.к. они уникальны и могут меняться.
Сделали команду, которая позволяет создать статью перед тест кайсами и еще команду для удаления после всех промежуточных тестов, чтобы она не засоряла БД.
TODO добавить команду очистки комментария в БД (если json-server не удаляет комментарии при удалении связанной с ней статьи, надо сначала проверить).

115. Моки. Стабы. Фикстуры. Скип тестов. Интерцепторы на запросы и фикстуры.
Создадим тест, который будет падать, чтоб словить ошибку. Представим, что на бэке что-то изменили и не предупредили фронт.
Но при этом засоряются отчёты, мы не можем прогнать релизную регрессию, вмёрджить ПР из-за этого.
В таком случае, если долго и трудно разбираться, можно скипнуть тест-кейс как it.skip().
Потом уже в рамках техдолга в отдельной задачи можно его исправить или удалить.

Второстепенные запросы, которые напрямую не требуются для тесткейсов (например тестирование только возвращаемых данных, а не того, как запрос отправляется),
можно мокать, чтобы не перегружать сервер. Плюс такие моки будут отрабатывать быстрее и стабильнее (т.к. настоящий запрос может отвалиться с ошибкой).
Создали пару json файлов с фикстурными данными в папке cypress/fixtures.
Их будем читать и использовать как ответ от сервера.
Можно автоматизировать процесс создания фикстур и переиспользовать.
В тесткейсах фикстуры используются в такой конструкции cy.intercept('GET', '**/articles/*', { fixture: 'article-details.json' }).
Термин "Стаб" это синоним "мок" - фейковые подготовленные данные (для имитации запроса).
В ui от cypress при выполнении тесткейсов на замоканном запросе будет флаг "no alias", при наведении на который можно убедиться в том, что он замоканный.
Если тесткейсов не оч много (не более 100), то можно в ручном режиме добавлять в каждый кейс интерцепторы.
Можно разделять на 2 discribe тесты с моками и с реальными запросами.

В командах можно не только добавлять новые, но и перезаписывать существующие (Cypress.Commands.overwrite) - пример в commands.ts.
Должны быть так же библиотеки, которые делают это автоматизированно.

Когда делаем какую-то задачу, создаём ПР. Там прогоняются тэсты. Представим что команда большая (30-40 человек).
Для каждого ПР прогоняются 100-500 тест-кейсов и они начинают спамить на сервер много запросов (которые еще и не стабильны).
Это все может тупить, ломаться, флапать и всех это будет бесить, никто к тестам серьёзно относиться не будет.
Поэтому с запросами в dev режиме можем работать в рамках фикстур. Перед релизом уже прогоняются тесты один раз и там летят настоящие запросы (и сохраняют новые фикстуры).

116. Изолированные тесты на компоненты с Cypress.
В cypress есть возможность тестировать компоненты в изоляции.
Отличие от RTL в том, что cypress компонент рендерится в браузере и мы нажимаем на реальные кнопки, вводим в реальные поля.
А в RTL используется виртуальная среда (jest dom) и не всегда может поймать баг (т.к. поведение эмулируется).
Но опять же, в браузере тесты прогоняются дольще, они менее стабильные и поддерживать их сложнее более стабильные RTL.
RTL - это классические юнит тесты, а компонентные тестирования на cypress - интеграционные. В них нужно писать какой-то важный функционал.
В приложении cypress выбираем "Component testing", выбираем фреймворк (у нас webpack).
Будет создана папка cypress/component.
Так же компонент нужно обернуть в стор, сделали изменения в src/shared/lib/tests/componentRender.
Вынесли TestProvider для переиспользования в e2e.
Там так же добавили ThemeDecorator и импорт глобальных стилей из app,
чтоб в тестах в браузере компоненты выглядили как в приложении (для RTL они были не нужны, но если будут ничего страшного).

Если подытожить e2e тесты прогоняются в браузере с данными сервера (в таком виде как на проде). А компоненты - изолированные тесты число для них, но более приближенные к проду.
ТАк же можно в Cypress.Commands.overwrite определять обертку провайдеров.

117. Prettier для форматирования кода. Интегрируем с eslint.
Можно настроить линтер так, чтобы он расставлял пробелы, запятые, делал нужные строчки, символы в табах и в целом нас это устраивает.
Но линтер, это инструмент, который используется немного для другого.
Линтинг - это в первую очередь статический анализ кода, на соответствие каким-то правилам.
Причем правила могут быть сколь угодно сложные и разные. В т.ч. мы написали много своих правил.
А за форматирование кода (в первую очередь) должен отвечать prettier.
Настраивать легко. Установили его как дев зависимость. Создали конфиг .prettierrc.json.
Так же создали .prettierignore, чтоб он не форматировал определённые файлы/директории.
Для запуска yarn exec prettier . --write
Но часть правил уже задано линтером, в доке есть раздел с интеграцией lint (и со stylelint тоже).
Установили в дев деп пакет eslint-config-prettier. И в .eslintrc.js добавили в extends prettier.
В доке указано что правила всегда побеждают extends (т.е. они приоритетнее чем расширение какого-то конфига).
Поэтому от ненужных правил нужно избавиться или переопределить.
Поубирали в линт конфиге правила отступа, max-len
Чтоб prettier заработал, нужно включить его в настройках вебшторма (по поиску prettier, я включил авто поиск конфига).
Теперь на форматирование (Ctrl + S или Ctrl + Alt + L) код форматируется.
Чтоб вернуть правила в претиер как это было через линтер, можно открыть https://prettier.io/docs/options
И там найти нужные свойства и вставить их в конфиг преттиера.
Иногда, если вебшторм не применяет форматирование преттера, то нужно его выключить и включить.
Всё форматирование как правило вкусовщина, нужно настраивать под себя, по согласованию с командой.
tabWidth - длина таба,
semi - в конце точки с запятой
singleQuote - одинарные ковычки на проекте
trailingComma - запятая в конце (лучше добавлять)
bracketSpacing - пробел между скобками {} и значением внутри
bracketSameLine - перенос jsx последней скобки (>) на новую строку
arrowParens - обертка в скобочки аргументов стрелочных функций
добавили в линтер правило react/jsx-max-props-per-line (чтоб максимум 3 пропса в компоненте на линию было), это правило расширит конфиг преттира.
Добавили скрипт prettier в package.json, чтобы он выравнивал весь проект.
Так же в package.json есть lint-staged, там расширили "**/*.{ts,tsx}": ["prettier --list-different", "eslint"]
Будет проверять только для измененных файлов в момент прекоммита.
У меня почему-то через yarn exec не получалось форматировать, через npx заработало.
Потом запустили проект, чтоб убедиться что он не сломался

118. Облачный сервер. SSH. Git. Удаленный сервер.
Сейчас есть деплой на netlify, он простой и никакого опыта не даст.
Сделаем деплой на свой облачный сервер с SSH, Nginx. Чтоб было базовое понимание.
Используем selectel.ru
После создания сервера у него будет ip-адрес, по которому он доступен.
Работа с сервером через ssh ключ. Возможно сначала установить ssh клиент.
Для подключения к серверу, в powershell вводим команду ssh root@<ip-address-server>
Вводим пароль, который в админке selectel.
После этого подключены к серверу удаленно, в этом же терминале. Там доступна вся ОС.
В начале лучше сделать sudo apt update (чтоб могли устанавливать правильные версии пакетов).
В первую очередь нужно установить node (лучше nvm) и git (sudo apt install git-all).
Нужно будет клонировать свой проект на сервере. Но он должен быть публичным.
Для приватного нужно будет сгенерировать ssh ключ внутри ubuntu сервера для работы с git-репозиторием.
После генерации заливаем публичный ключ на гитхаб в настройках аккаунта (deploy keys).
После этого можно клонировать проект.
Устанавливаем ноду той версии, которую использовали в разработке (у них 17.4.0, у меня 20.11.1).
При необходимости установить другие пакеты (например yarn).
Потом устанавливаем зависимости проекта.
Потом пробуем стартовать yarn start:dev.
Если запустится, копируем ip-адрес и вставляем в браузер с нужным портом (8000 - сервер, 3000 - фронт).
Сейчас он раздаётся как дев сервер, не минимизированный и не сжатый, но работает.

119. Nginx. Конфигурация. Взаимодействие с сервером.
Nginx — это высокопроизводительный веб-сервер (для веб-сайтов с высокой посещаемостью) и проксирования.
Научимся запускать nginx, раздавать статику, сбилженные файлы проекта.
Для установки команда sudo apt install nginx.
В папке <root>/etc появится папка nginx. В ней будет вся конфигурация.
vim default - переход в файл конфига.
Можно удалить все коменты, чтоб было проще читать.
listen 80; - прослушиваем 80 порт.
root - папка, в которой находится статика (html).
location - по каким адресам доступно (у нас по всем после слеша, если что-то не найдено, будет присылаться 404).
Для проверки, что всё доступно команда nginx -t, должно быть написано syntax is ok.
Можно перезапустить nginx командой sudo service nginx restart
чтобы гарантировано конфигурация была актуальная.
В ОС, в папке будет /var/www/html будет index.nginx-debian.html
Нужно создать папку, указанную в конфиге (у них production_project).
Переходим в неё. Внутри создаём папку html.
Возвращаемся в проект, запускаем сборку yarn build:prod, то там мы передавали переменные окружения для vercel.
Передадим туда вместо этого ip адрес сервера, типа такого:
webpack --env mode=production apiUrl=https://00.00.000.000:8000
После сборки будет папка build со сборкой. Её нужно переместить в var/www/production-project/html
командой mv root/production-project/build/ var/www/production-project/
Там будет html файл и build папка, которую надо переименовать в html
В папке html должна быть сбилженная статика (css, js, html файл)
Можно перейти на ip-адрес (без портов), будет доступна прод сборка.
Но бекенд еще не будет запущен. В папке проекта запускаем только сервер yarn start:dev:server
Будет бэк и фронт работать по одному адресу, но на разных портах.
После запуска можно пробовать логиниться.
Еще есть ньюанс, если перейти на вложенный роут (например /about) и перезагрузить страницу, то вернется 404.
Поскольку это SPA и index.html файл всего один.
Нужно чтобы все запросы отправлялись именно в этот единственный index.html файл.
А роутинг будет за счет react-router.
Нужно поправить конфиг nginx.
Переходим cd etc/nginx/sites-enabled/
Там vim default (открываем конфиг).
там вместо 404 ошибки вписать /index.html; (будет редирект).
сохраняем - esc : v q
Перезапускаем nginx.

120. nginx gzip. Сжимаем файлы. Подключаем домен. pm2 для сервера.
Подключаемся к серверу, заходим в папку nginx.
vim nginx.conf - редактирование главного конфига nginx.
В нем есть настройка, которая подключает все файлы, находящиеся в папке sites_enabled.
Есть настройки, связанные с gzip, для сжатия файлов.
Если на сервере перезагрузить страницу со сбросом кеша, то прод бандл будет весить 435 кб.
6 уровень сжатия по дефолту, всего 9.
Рекомендуется сильно не сжимать, иначе не получим выгоду, т.к. на сжатие уходит время (должна быть золотая середина, 5-6 уровень норм).
В gzip types указываются типы файлов, которые будут сжиматься
Если раскомментировать gzip настройки, сохранить конфиг и перезагрузить nginx, то main бандл уже будет весить 137 кб.

Далее нужно сделать доменное имя, чтобы не заходить на сайт по ip-адресу.
Есть сайт reg.ru - регистратор доменов (подобных сервисов полно, можно использовать любой, настройки +- одинаковые, только ui отличается).
Нужно там зарегаться, потом перейти на "Зарегистрировать домен" и ввести домен, который нужен (желательно более уникальный).
Выбрать домен верхнего уровня (ru, com и т.п.).
Покупаем (рублей 150 в год). Они обычно дешёвые.
Отключаем "хостинг на месяц", "SSL" (т.к.у нас свой ssh будет).
После покупки идём в личный кабинет. Находим домен, будет написано "домен не подключён к сайту".
Во вкладке DNS серверы нажимаем на кнопку "Изменить".
В "Ресурсные записи" добавляем ip адрес своего сервера, для привязки домена к нему.
Добавляем для одной @ (subdomen) записи и еще для www записи (чтоб был доступен при указании www.<домен>).
После этого необходимо настроить ДНС серверы.
В selectel (где покупали сервер) нужно добавить домен.
Открываем панель управления. Указываем и добавляем купленный на reg.ru домен (без http:// только домен и домен верхнего уровня типа site.ru).
После добавления необходимо делегировать домен (передать управление доменом на DNS-серверы selectel).
Переходим в доменный регистратор, выбираем настройку ДНС серверов, добавляем свой список (как в рекомендациях).
ns<1-4>.selectel.org. Подтверждаем и ждем успешного выполнения операции (может быть не быстро, до 24 часов).
Спустя какое-то время на reg.ru появится запись "Для управления ресурсными записями обратитесь к провайдеру, предоставившему вам эти ДНС".
Это те тамые "А" записи. Т.к. мы их изменили, но нужно их указать на стороне selectel.
Переходим на вкладку домена в selectel. Добавляем запись типа @ и ниже ip-адрес сервера (то же самое для www).
Т.е. добавляем 2 записи типа "А" (то же самое что делали на reg.ru, чтобы они были доступны по этому адресу).
Нужно подождать какое-то время, пока ДНС сервера проверятся. Спустя какое-то время, перейдя по домену, откроется приложение.
Т.е. ДНС сервер сопоставил ip-адрес с доменным именем и определил что нужно открыть наше приложение.

Далее нужно настроить pm2 (Process Manager) для запуска NodeJS json сервера,
чтобы он не отключался после закрытия терминала (работал 24 на 7).
Подключаемся к серверу, переходим в папку с проектом. Нужно глобально установить pm2 (npm install mp2 -g).
Он позволяет запускать процессы, убывать, поднимать, если они по какой-то причине умерли, держать их в фоновом режиме и т.д.
pm2.keymetrics.io - дока. Есть инфа на канале.
Для запуска команда - pm2 start <название файла js>.
Т.е. pm2 start /json-server/index.js
Пробуем авторизоваться, если запросы улетают успешно, значит сервер запущен.

121. SSL. Сертификат. Настраиваем https.
То, что настраивали ранее, работает поверх http.
При попытке перейти на https, то приложение не откроется, т.к. для него мы дополнительно ничего не настраивали.
Для быстрого получения сертификата и настройки https можно использовать Let's Encrypt.
Можно зайти на их сайт, почитать описания. Открываем ссылку на certbot.
Нужно указать на чём запущен http сервер (у нас nginx, так же указать версию ОС - Ubuntu (она отображается в selectel в консоли, либо в конфигурации)).
Далее можно следовать инструкции. Подключиться по SSH к серверу, установить snapd.
Вероятно на ubuntu он уже предустановлен (проверка snap --version).
sudo snap install core; sudo snap refresh core
При необходимости нужно удалить существующий certbot (если раньше настраивали).
устанавливаем бот sudo snap install --classic certbot
Подготовка бота ... (идем по пунктам, все описывать не буду).
После этого соглашаемся со всем что предлагается. Указываем рабочую почту, домен (site.ru).
Может быть ошибка настройки server_name. Нужно перейти в директорию sites-enabled => vim default.
Напротив server name указать название домена (site.ru www.site.ru).
Сохраняем Esc :wq , проверяем синтаксис nginx -t
sudo service nginx restart
Вызываем команду с настройкой certbot еще раз.
Вводим указанные server name
Если он скажет что уже есть, то передаем e, чтоб он его расширил.
После этого можно перейти на сайт под https и он должен открыться.
При запросах будут ошибки, т.к. клиент находится на https, а запросы делается на сервер под http.
С точки зрения безопасности так делать нельзя и браузер такой запрос блокирует.
Нужно сделать некоторые изменения в nodejs json-server/index.js.
Так же это можно обойти через проксирование самого nginx.
Можно гуглить node js https.
Внутри проекта в терминале openssl genrsa -out /json-server/key.pem (если под виндой, то вероятно нужно через git-bash).
... все описывать не буду, команды меняются в зависимости от версии node ...
В файле index.js с сервером тоже правки. Импорт https, создание сервера https, передаем опции и наш сервер.
Раньше на 8000 порту был сервак, сейчас можно указать 443 - дефолтный для https.
Из скрипта build:prod нужно удалить переменную окружения apiUrl, чтоб можно было его извне передавать когда это необходимо.
Отправляем изменения на гитхаб, чтобы подтянуть этот код на облачном сервере.
На сервере переходим в папку проекта, спуливаем свежую версию из репозитория.
pm2 list - видим что запушен старый процесс nodejs приложения.
pm2 stop 0 (0 - это номер процесса слева в таблице) - останавливаем его.
и заного его запускаем pm2 start /json-server/index.js
Если попробуем перейти на сервер через ip:443 то ошибка подключения (не защищено), но главное, что сервер под https работает.
Вероятно нужна какая-то доверенность (недействительный сертификат). Но это не важно, т.к. бэк фейковый главное настроить фронт на стабильную работу с https.
Поменяем порт для httpServer на 8443, чтоб не было конфликта потом с фронтом с nginx.
Снова заливаем на гитхаб, спуливаем на сервере, обновляем процесс в pm2.
Снова делаем прод сборку фронта на сервере, в качестве apiUrl указать бэк который работает поверх https.
yarn dev:prod apiUrl=https://00.00.000.000:8443
После успешного выполнения сборки нужно переместить статику в папку, которая раздаётся nginx (/var/www/production-project).
Старую удаляем и закидываем новую.
rm -rf var/www/production-project/html/ - удаление
mv ~/production-project/build/ /var/www/production-project/html - перемещение
через ls проверяем наличие файлов и папок.
После этого проверяем работу приложения, как проходят запросы авторизации. Должно норм отрабатывать.
После отравки запроса возникнет проблема протухшего сертификата (пофиксим в след уроке).
https на фронте начал работать за счет добавления настроек от certbot в конфиг nginx (vim default) (прослушивание 443 порта, указал сертификаты и т.п.).
Можно получившийся конфиг (nginx cat) скопировать и добавить в проект в файл nginx.conf, чтоб лежал на гитхабе в исходниках и его можно было посмотреть (технически ни на что не влияет).

122. Проксирование запросов. Query params.
Сейчас мы все адреса указываем на пряму (/login, /article/1) и получается, что какая-нибудь страница /login может совпасть с ендпоинтом /login на сервере.
Хочется это явно отделить, плюс на самом nginx сделать проксирование таких запросов строго на бэкенд.
Можно посмотреть шпоргалку https://www.dmosk.ru/miniinstruktions.php?mini=nginx-redirects#proxypass
Проксирование похоже на редирект, только оно касается запросов. Это когда мы отправляем запрос на один адрес, он редиректится на другой и по итогу возвращается ответ.
Т.е. это грубо говоря перенаправление запроса с одного на другой.
Чтобы это проксирование реализовать нужно указать несколько настроек (location) в конфиг nginx.
Идея в том, что все запросы, которые включают в себя /api, будут перенаправляться на бэкенд.
В proxy_pass нужно указать ip:port куда запрос нужно перенаправить
После изменения конфига nginx заново собираем сборку с указанием apiUrl=https://site.ru/api (в конце /api).
Снова удаляем старую папку с билдом, переносим новую.
При проверке приложения, если запрашивать фронтовые роуты, то будет переход по роутам, если /api/адрес, то запрос по эндпоинту с бэка.
Это осуществляется за счёт проксирования на nginx.
Так же если перейти по роуту /profile/1, то во вкладке network будет запрос на /api/profile/1
(т.к. сам запрос в компоненте, но проксируется (304 код перенаправления) nginx и по итогу возвращает валидный ответ).
После этого должна исчезнуть ошибка не безопасного соединения, которая была в прошлом уроке.
Важно ещё не забыть про локальную разработку. Т.к. при локальной разработке мы используем фейковый json-server и должен запускаться и юзаться http сервер (без лишних сертификатов и заморочек).
Просто рядом создается http сервер с другом портом (порты можно прокидывать через переменные окружения)
При проксировании не было учета query параметров и они не отправлялись в запросах на облачном сервере.
Нужно в конфиге nginx поправить регулярку ($1$is_args$args).

123. Скрипт для деплоя. getApiUrl.
Нужно чтоб процесс деплоя был удобным.
Чтоб при изменении кода и пуше в удалённый репозиторий на облачном репозитории эти изменения применились.
Сейчас необходимо руками спуливать на сервере актуальный код, запускать билд прод сборки, удалять старую статику, переносить новую статику.
Для автоматизации этих процессов есть 2 варианта. Либо собрать докер файл, который будет автоматически запускать внутри себя установку nginx и т.д.
Либо можно сделать простой bash скрипт, который эти ручные действия будет делать автоматически.
В докере тут очевидно нужды нет, т.к. это избыточно для простого проекта, в котором нужен ли nginx и статика.
Поэтому сделаем bash скрипт.
Создаем в корне папку .deploy/deploy.sh и .deploy/nginx.conf
В deploy.sh пишутся все эти команды, которые писались в ubuntu на облачном сервере.
т.е. переход в папку проекта, прод сборка, удаление старой статики, перенос новой статики в var/www/production-project/html
После этого, при изменении кода и пуша его в репозиторий, на сервере достаточно спулить и запускать bash скрипт (предварительно дав доступ на выполнение chmod +x deploy.sh).
Будут по очереди запускаться процессы и команды и через какое-то время проект обновится.
Это самый простой вариант написания bash script который минимизирует кол-во ручных действий на сервере.
С докером это было бы избыточно, т.к. простое приложение со статикой, даже нет SSR.
Если бы мы собирали различные тестовые версии (беты) под разные окружения (тест, прод, релиз), то можно было бы сделать через докер.
Для примера, что происходило бы в докере.
Сначала создается докер на основании версии Node.
Потом package.json копируется внутрь, устанавливаются зависимости, копируется все что необходимо, происходит сборка.
Потом на основе nginx образа переносится конфиг в нужную папку, удаляется папка html... (по сути все те же самые действия, что мы делали, только они изолированы в рамках докер контейнера).
Так же можно по SSH подключаться к удаленному облачному серверу в процессе github actions в yml файл для CI.
В secrets сохраняются host, username, password, port и т.п. Указываем нужный скрипт и можно к серверу по SSH подключаться.
И далее выполнять любые команды на сервере, например запустить наш bash скрипт на ребилд прод сборки.
secrets можно указать в настройках репозитория (settings/secrets and variables)

124. Селекторы с аргументами. Типизация buildSelector.
Нужно улучшить buildSelector, чтобы в него можно было передать аргумент.
Добавили передачу args в хук и типизации. 
Можно не использовать useSelector со сложными колбеками внутри.

125. Модели ветвления Git. Trunk based vs Git Flow.
Самые частно используемые модели ветвления git это две: git flow и trunk based.

GIT FLOW.
В git flow ветка master это основной источник истины, там должна быть работоспособная версия приложения, в неё обычно мерджат лиды.
Ветка dev для разработки, он неё отводится ветка с фичей для разработки и как правило, если фича большая, то эта ветка живёт очень долго (месяцы).
От этой ветки могут отводиться еще более мелкие ветки с задачками (аля эпик).
Потом, когда фича закончена, протестирована, убедились что нет багов, эт все вливается в develop ветку.
Такой подход хорош тем, что в develop не попадает сырой и недоработанный код.
Из минусов, за счёт того, что ветки живут долго, другие участники команды, за то время пока разрабатывается фича, делаю много коммитов.
Состояние из которого делали ветку и состояние в которую потом заливается фича очень разнятся и это черевато конфликтами и багами при мёрдже.
Релизные ветки создаются от develop и потом мерджатся в master после тестирования.
Т.е. основное отличие от TRUNK BASED в том, что есть ветка develop и ветки под фичи живут дольше.

TRUNK BASED.
В этом подходе нет ветки develop. От master делаются фичи и потом мерджатся в master после тестирования.
Так же от master отдельно и пареллельно фичам делаются релизные ветки, которые после тестирования и релиза мерджатся в master.
Так же при таком подходе ветки не живут долго (короткоживущие).
Допустим есть большая фича на месяц, разработка новой страницы. Она декомпозируется на более мелкие подзадачи и после выполнения сразу мёрджатся в master/
Иногда подмёрдживания делаются сразу без тестирования тестировщиком (только разработчиком, он смотрит что ничего не сломал и мерджит в master).
И за счет короткого срока жизни задач, получается что их состояние максимально приближено к ветке master.
Т.к. в ветке master может быть сырой код, то функционал может прятаться за feature флаги (isNewFeatureEnabled: true\false).
Для каждого пользователя этот флаг имеет своё значение. По-умолчанию, когда фича создаётся, этот флаг у всех равен false.
И получается что новый функционал, который разрабатывается пользователю еще не доступен (компонент не отрисовывается).
Тоже есть определённые риски, иногда что-то может "протечь". Но силами разработчиков и тестирования это должно выявляться.
Так же такой подход может быть и в GIT FLOW, если хочется какой-то функционал спрятать. Например экспериментальный функционал,
который хочется реализовать и посмотреть как пользователи на него отреагируют.
Мы для 10% пользователь этот функционал включаем, смотрим на метрики, видим что фича показывает себя хорошо, потом включаем его для 50%.
Еще немного тестируем и потом на 100%. Плюс если выкатили фичу, в ней появилсь какие-то проблемы и баги, эту фичу всегда можно откатить.
Т.е. прям в релизе, в проде, в любой момент фичу можно отключить, поменять флаг в БД для всех пользователей.
И тем самым устраняется баг без хотфиксов, без новых релизов.
Но фиче-флаги хорошо сочетаются именно в trunk based. Т.к. можно заливать сырой функционал пряча его за фиче флаг и не опасаясь за баги.
В git flow тоже используется, но не в таких объёмах, а в trunk based почти все на фиче флагах (кроме багфиксов, минорных задач).
А в git flow прячутся какие-то большие куски, либо опасные куски, которые хочется в любой момент откатить, либо экспериментальные куски.

Если подытожить, основные различия:
1) В git flow есть прослойка в виде develop ветки, фичи, более мелкие фичи от фичей покрупнее (отдаляемся от master ветки).
В trunk based мы максимально преближены к master ветке.
2) в trunk based коротко живущие ветки от master, в git flow фичи от ветки develop.
3) отличия в релизах. В git flow, в develop сходятся в кучу все фичи. От develop ветки делается релиз, ставилизируем его, фиксим баги
и только потом мёрджим в мастер. И ветка master - это самая актуальная версия прода (вероятно при мердже в неё автоматически ребилд).
В trunk based от главной ветки отводится релиз, тестируется и фиксятся баги и релизимся. Если в проде выявляется баг и есть понимание в чем проблема и кпак фиксить,
и откатить фиче флаг - то проблема решена. Если по откату фичче флага проблема не решается, то релизная ветка откатывается на предыдущий шаг.
Делается хот фикс проблемного релиза и вновь его выкатываем. Более сумбурный процесс релизов, но он позволяет делать релизы очень часто.
4) git flow подходит для разных по составу команд (т.е. там вероятность допустить какую-то ошибку ниже).
trunk based больше подходит для опытных команд, которые могут работать слаженно и быстро.
5) Для trunk based хорошо подходят микросервисы, SPA, мобильные приложения, распределенные системы (прототипы) чтобы делать быстро.
trunk based он больше про скорость, но есть цена ошибки.
git flow больше подходит для комплексных, монолитных, больших и стабильных приложений. Где разрабатывать одну фичу месяц - это норма.
Ну и рефакторинг легаси проекта (brownfield) тоже больше для git flow.
6) По вопросу deploy и релизов. В git flow возможны самые различные варианты (конвеер, ручная выкатка). Возможны долгие релизы.
В trunk based чаще всего используется конвеер с автоматически настроенными процессами сборки (CI-CD pipelines, testing, automations),
чтобы максимально быстро релизы делались. Без этого trunk based теряет смысл, т.к. важна скорость.
7) Нельзя сказать что что-то одно лучше другого, просто у подходов разные приоритеты.
В trunk based приоритеты на скорость, непрерывность, конвеер (agile, спринты).
В git flow приоритет на стабильность, не сломать то что уже существует, все качественно тестировать.

Концепция Feature flags. Постепенное внедрение новых фичей.
Компоненты фичей рендерятся по условию фиче флага. Сами фиче флаги хранятся в БД, чтобы их можно было в любой момент переключать.
Причём хранятся они для каждого пользователя отдельно. 
Сделаем такие фиче флаги в нашей БД, внутри пользователей в поле features (isArticleRatingEnabled, isCounterEnabled).
Создали shared/types/featureFlags (в shared т.к. везде могут понадобиться).
Так же создали shared/lib/features
Мы сделаем фиче флаги не реактивными. Т.е. в стейт сохранять не будем. при смене сессии сохраняются куда-то в константу.
Если фиче флаги поменяются интерфейс перерисовываться не будет (т.к. реакт не подписывается на это, не реактивно).
У НАС ФИЧИ НЕ МЕНЯЮТСЯ В ХОДЕ СЕССИИ, ИХ НЕОБЯЗАТЕЛЬНО ДЕЛАТЬ РЕАКТИВНЫМИ!
Сама константа фиче флагов без экспорта. Снаружи доступа к ней не имеем. Чтоб случайно её не изменить.
Если хотим прочитать какой-то флаг, то будем использовать геттер.
Для изменения будем использовать сеттер (явно менять).
Добавили в интерфейс user фиче флаги.
В экшенах setAuthData и initAuthData вызываем сеттер фиче флагов.
В компонентах сделали условный рендеринг.
Есть и минус, если фиче флаги куда-то в глубь прорастают, типа в экшены, сеелкторы, хелперы. Усложняется система.
Дальше будем эту проблему решать.

126. Унификация работы с флагами. Автоудаление старых фич.
Фиче флаги можно использовать не только как условие отображения фичей, но и как обновление UI.
Например есть старый компонент и новый компонент (редизайн).
Хочется сделать новый, не удаляя при этом старый, чтоб экспериментально его зарелизить и посмотреть как он зайдет для пользователей.
По условию отрисовывается новый или старый компонент.
В какой-то момент когда все тесты прошли, он старого кода избавляемся и оставляем только новый.
По итогу при выпиливании старой фичи может потребоваться много времени на определение, куда эта фича ещё проросла (функции, компоненты).
Кодовая база будет обрастать фичами, не будет желания их выпиливать.
Нужно придумать функционал, благодаря которому мы сможем автоматизировать и унифицировать работу с фиче флагами.
реализуем функцию toggleFeatures, которая будет принимать название фичи, старый и новый функционал.
Так функционал не прорастает в код и для переключения нужно будет использовать функцию toggleFeatures.
По итогу можно написать скрипт, который можно вызывать, передавать название фичи.
Этот скрипт будет обходить весь проект, находить использование функции toggleFeatures и удалять лишний код (т.е. оставлять только новый код).
Либо оставлять только старый (если эксперимент не удался).
Тем самым мы запрещаем разработчикам руками использовать фиче флаги, чтобы они прорастали в код, чтобы про было выпиливать.
Плюс мы еще настраиваем автоматику.
Создали shared/lib/features/toggleFeatures.
Реализовали скрипт scripts/remove-feature.ts для удаления фиче флагов с оставлением нужного функционала.

Для понимания как работать с AST можно скопировать туда код компонента целиком и смотреть как называются ноды и какие у них методы или поля.
В transform можно выбрать typescript.

В текущей реализации есть правила использования. Нужно передавать именно стрелочную функцию в on или off, объявленную в другом месте.
Можно написать линтер, чтоб запрещал внутри тела функции объявлять переменные и т.п., чтоб в одну строку передавалась функция, объявленная в другом месте.
Пример использования в src/pages/ArticleDetailsPage/ui/ArticleDetailsPage.

127. Json Settings. Настройки пользователя. Localstorage на максималках.
Тема сохраняется в localStorage браузера.
Хотелось ты подобную общую информацию аккаунта сохранять, чтоб в разных браузерах отображалось одинаково.
По возможности надо просить бэкендеров сделать jsonSettings (хаотичные настройки, привязанные к аккаунту, которые определяет фронт).
У нас там будет theme, isFirstVisit, settingsPageHasBeenOpen.
У таких настроек нет жесткой схемы, там можно хранить рахные данные и постоянно менять/расширять их.
Например, тема, язык, разрешение на получение уведомлений/пушей, первый визит, проверять какие-то страницы, были ли открыты или нет,
видел ли пользователь новый блок, чтоб показать ему всплывающую подсказку.
Т.е. второстепенные настройки, которые можно сохранять с фронта на бэк, при этом бэк даже не знает, что там сохраняется.
Создали под это схему src/entities/User/model/types/jsonSettings.ts
Создали селектор получения данных из стор.
Изменили useTheme, чтоб определялась тема извне.
В toggleTheme передаем колбек saveAction, в котором уже будет во вне определяться где сохранять (localStorage, сервер, indexedDB и т.д.).
Раньше всегда для rtk-query использовали хуки для запросов.
В rtk-query есть возможность выполнения запроса и без хуков (метод initiate()).
С помощью него можно отправлять запрос не только в компонентах.
В санке используем, с методом unwrap() для разворачивания промиса (чтоб reject тоже обрабатывался в санке).

128. Запрос на получение пользователя. Избавляемся от заглушки в Localstorage.
Сейчас в localStorage хранится весь authData от пользователя. Какие-то данные не актуальные что вызывает ненормальное поведение (смена темы).
Нужно данные подгружать с сервера, чтобы они были максимально актуальными.
Сделали localStorage.setItem в экшене setAuthData. Вообще редьюсеры это должны быть чистые функции и сет данных в localStorage
не очень корректен. Но чтобы это было в 1 месте, решили сделать так.
Сделали запрос getUserDataById, теперь вместо localStorage данные будет брать оттуда.
Важно понимать, что в реальном проекте был бы токен в localStorage, а не id.
В App.tsx сделали инит запрос. Так же нужно понимать, что запрос занимает время и нужен loader.
Пофиксили инициализацию темы в провайдере.

129. Практическое применение json settings. Работа с новыми пользователями.
Когда пользователь в 1 раз авторизуется и заходит на страницу статей, мы хотим показывать для него модалку.
Сделали src/features/articlePageGreeting
Добавили модалку в ArticlesPage.tsx. Будет открываться по условию isArticlesPageWasOpened из jsonSettings.

130. ToggleFeatures. Обвязка для работы с компонентами. Автоудаление.
Реализуем компонент shared/lib/features/ToggleFeatures для рендера компонентов по фиче флагу,
а функцию toggleFeatures оставим для функций/хелперов.
Так будет семантически правильнее и удобнее работать.
Преимущество в том, что мы работаем с компонентами так же, как если бы мы работали, если б toggleFeatures и не было.
Так же поработаем со скриптом, чтобы он умел обрабатывать jsx. И добавили его в package.json

131. Макеты. Layout. Гриды. Шрифты. Цвета.
Новый дизайнер сделал обновлённый макет, будем его реализовывать.
Добавили новый фиче флаг isAppRedesigned.
У всех пользователей он будет выключен, а у админа включен. Т.е. только админ будет видеть в начале обновление дизайна.
Одновременно будет и старый и новый дизайн.
Сперва перенесли всю цветовую палитру в тему, т.к. на них всё основано (так же как шрифты или отступы).
Через google-font выгрузили новые шрифты, в head в index.html (из public) вставили.
TODO нужно будет в title сделать заголовок для сайта (т.к. сейчас document). Можно так же фавикон добавить.
В App.tsx используем ToggleFeatures для рендера нужной версии приложения по фиче флагу.
Изменили Sidebar, в нем так де использовали ToggleFeatures.
Можно при желании создавать рядом компоненты, типа SidebarDepricated, SidebarRedisigned. Но мы в одном файле делали условные рендеры разметки.
Добавили layout, которые будут находиться в shared слое (shared/layouts). Зачем? не понятно. TODO подумать над перемещением в app (погуглить).
В MainLayout добавили еще toolbar, там будет кнопка скрола к шапке, но подразумевается, что там могут быть и другие инструменты управления страницей.
В Page так же внесли изменения с ToggleFeatures. То же самое в Navbar.
TODO заменить AppImage на другой логотип под себя (вероятно такой же для фавикона).

132. SVGR. Обработка размеров и цветов иконки на этапе сборки.
В иконках svg есть местами fill. Плюс размеры задаются не совсем корректно.
Чтоб во всех местах не менять, мы используем SVGR loader.
Будут размеры и цвета из иконок выпиливаться и ими можно гибко управлять через css или пропсы компонента.
Сделали изменения в config/build/buildLoaders.ts, добавили плагины с настройками.
Иконки некоторые стали меньше, т.к. по дефолту размер 1em.

133. Редизайн UI kit. Помечаем старые компоненты deprecated.
Добавили новые иконки.
Сделали shared/ui/deprecated и переместили туда все текущие компоненты из shared/ui.
Мы помечаем, что не будем их больше поддерживать и обновлять.
Если там будут баги, то это на ответственности пользователя.
Можно выводить сообщение пользователю, типа "если хотите - используйте старый ui, но мы его больше не поддерживаем и там могут быть баги".
Так делают во многих местах, с новыми версиями ОС и т.п., поддержка заканчивается.
Каждый компонент в deprecated так же пометим в комментах, что он deprecated.
Webstorm Будет такие компоненты зачёркивать.
Потом по ходу разработки будем определять какие компоненты действительно deprecated, а какие еще актуальны, но требуют доработки.

134. Редизайн Sidebar. Иконки. Кнопки. Ссылки.
Создали папку shared/ui/redesigned.
Енамы в компонентах заменили на union типы, так проще работать с ними.
TODO надо будет написать сторисы для shared/ui/redesigned компонентов.
Внесли изменения в виджет Sidebar, отрисовка элементов по фиче флагу.
Для Icon сделали 2 типа пропсов (clickable и not-clickable, чтоб правильно подтягивались типы).

135. Редизайн Navbar, dropdowns, работа с текстом.
Пофиксили лэйаут, чтоб растягивался при сворачивании Sidebar.
Редизайнили хеадер.

136. Sticky Layout для статей. Редизайн табов, фильтров.
Поломалась логика обработки скрола (перешла на документ).
Починили useInfinityScroll. Передали там для нового дизайна в качестве wrapperRef undefined, чтобы в конфиг попало null.
Если null, то берется дефолтный браузерный viewPort согласно доке.
Сделали StickyContentLayout для реализации sticky сторон и контента по-середине со скролом.
В некоторых случаях приходится плодить лишние ноды когда требуется поведение Stack.
Например, внутри Card вкладывается HStack и внутри него items.
TODO можно реализовать это через передачу в classNames, в качестве additionals в массив хелпер (типа миксин) getHStack({ gap: '16', justify: 'center' }). или getVStack.
Функция возвращает набор классов в соответствии с опциями, которые мы передали.
Это нужно чтобы каждый раз руками не задавать одинаковые стили, плюс чтоб поддерживалась дизайн система (т.е. одинаковые gap 8 | 16 и т.д.).
Создали widgets/ArticlesFilters. Виджет, т.к. содержит в себе несколько фичей (поиск, табы и сортировка).

137. Addon left right. Инпут, кнопка. Pixel perfect plugin проверка.
Сделаем redesigned input и стрелочки в выпадающем списке.
Новый инпут будет без кастомной каретки.
Pixel perfect это плагин не для 100% соответствия пиксель в пиксель как в макете, а скорее для проверки соответствия.
Для очень точного соответствия стоить проверять и делать shared компоненты, а составные блоки уже можно подгонять примерно (но опять же зависит от требований проекта).

138. Редизайн карточки профиля.
TODO лучше декомпозировать компоненты на deprecated и redesigned (которые для компонента ToggleFeatures).
